{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of samples to generate\n",
    "n_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate service types (auto, bike)\n",
    "service_types = np.random.choice(['Auto', 'Bike'], n_samples, p=[0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate driver IDs (50 unique drivers)\n",
    "driver_ids = [f\"D{str(i).zfill(3)}\" for i in range(1, 51)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "data = {\n",
    "    'driver_id': np.random.choice(driver_ids, n_samples),\n",
    "    'timestamp': [(datetime(2024, 1, 1) + timedelta(hours=np.random.randint(0, 24*30))).strftime(\"%Y-%m-%d %H:%M:%S\") for _ in range(n_samples)],\n",
    "    'service_type': service_types,\n",
    "    'historical_acceptance_rate': np.random.beta(7, 3, n_samples),\n",
    "    'distance_to_pickup_km': np.random.exponential(2, n_samples),\n",
    "    'estimated_trip_distance_km': np.random.lognormal(2, 0.5, n_samples),\n",
    "    'estimated_trip_time_min': np.zeros(n_samples),  # Will calculate based on distance and traffic\n",
    "    'weather_condition': np.random.choice(['Clear', 'Cloudy', 'Light Rain', 'Heavy Rain', 'Snow'], n_samples, p=[0.5, 0.2, 0.15, 0.1, 0.05]),\n",
    "    'traffic_congestion_level': np.random.choice(['Low', 'Medium', 'High', 'Severe'], n_samples, p=[0.3, 0.4, 0.2, 0.1]),\n",
    "    'is_peak_hour': np.zeros(n_samples, dtype=bool),  # Will fill based on time\n",
    "    'hours_already_worked': np.random.gamma(3, 1, n_samples),\n",
    "    'accepted_ride': np.zeros(n_samples, dtype=bool)  # Will fill this based on other features\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract time features\n",
    "df['hour_of_day'] = df['timestamp'].apply(lambda x: int(x.split()[1].split(':')[0]))\n",
    "df['day_of_week'] = df['timestamp'].apply(lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\").weekday())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine peak hours (weekdays 7-10 AM and 5-8 PM, weekends 6-9 PM)\n",
    "def is_peak_hour(row):\n",
    "    hour = row['hour_of_day']\n",
    "    day = row['day_of_week']\n",
    "    \n",
    "    if day < 5:  # Weekday\n",
    "        return (7 <= hour <= 10) or (17 <= hour <= 20)\n",
    "    else:  # Weekend\n",
    "        return 18 <= hour <= 21\n",
    "\n",
    "df['is_peak_hour'] = df.apply(is_peak_hour, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate estimated trip time based on distance and traffic\n",
    "def estimate_trip_time(row):\n",
    "    distance = row['estimated_trip_distance_km']\n",
    "    \n",
    "    # Base speed in km/min (converted from km/h)\n",
    "    if row['traffic_congestion_level'] == 'Low':\n",
    "        speed = 0.5  # 30 km/h\n",
    "    elif row['traffic_congestion_level'] == 'Medium':\n",
    "        speed = 0.4  # 24 km/h\n",
    "    elif row['traffic_congestion_level'] == 'High':\n",
    "        speed = 0.3  # 18 km/h\n",
    "    else:  # Severe\n",
    "        speed = 0.2  # 12 km/h\n",
    "    \n",
    "    # Adjust speed based on weather\n",
    "    if row['weather_condition'] in ['Heavy Rain', 'Snow']:\n",
    "        speed *= 0.8\n",
    "    elif row['weather_condition'] == 'Light Rain':\n",
    "        speed *= 0.9\n",
    "    \n",
    "    # Adjust speed based on service type (bikes are faster in traffic)\n",
    "    if row['service_type'] == 'Bike' and row['traffic_congestion_level'] in ['High', 'Severe']:\n",
    "        speed *= 1.3\n",
    "    \n",
    "    # Calculate time with a minimum of 5 minutes\n",
    "    return max(5, distance / speed)\n",
    "\n",
    "df['estimated_trip_time_min'] = df.apply(estimate_trip_time, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate fare amount based on Namma Yatri pricing strategy\n",
    "def calculate_namma_yatri_fare(row):\n",
    "    distance = row['estimated_trip_distance_km']\n",
    "    time = row['estimated_trip_time_min']\n",
    "    service = row['service_type']\n",
    "    \n",
    "    # Set pricing based on service type for Namma Yatri\n",
    "    if service == 'Auto':\n",
    "        base_fare = np.random.uniform(30, 40)\n",
    "        per_km_rate = np.random.uniform(12, 15)\n",
    "        per_min_rate = np.random.uniform(1, 2)\n",
    "    else:  # Bike\n",
    "        base_fare = 30\n",
    "        per_km_rate = np.random.uniform(10, 12)\n",
    "        per_min_rate = 1\n",
    "    \n",
    "    # Calculate fare components\n",
    "    distance_fare = per_km_rate * distance\n",
    "    time_fare = per_min_rate * time\n",
    "    \n",
    "    # Total fare (Namma Yatri has no surge)\n",
    "    total_fare = base_fare + distance_fare + time_fare\n",
    "    \n",
    "    # Round to nearest 5 rupees\n",
    "    return round(total_fare / 5) * 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fare_amount'] = df.apply(calculate_namma_yatri_fare, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Namma Yatri, driver earnings equal fare amount (0% commission)\n",
    "df['driver_earnings'] = df['fare_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define acceptance probability based on features\n",
    "def calculate_acceptance_probability(row):\n",
    "    prob = 0.8  # Base probability\n",
    "    \n",
    "    # Adjust based on historical acceptance rate (strong factor)\n",
    "    prob += 0.15 * row['historical_acceptance_rate']\n",
    "    \n",
    "    # Adjust based on distance to pickup (negative factor)\n",
    "    prob -= 0.05 * min(row['distance_to_pickup_km'], 10) / 2\n",
    "    \n",
    "    # Adjust based on earnings (positive factor)\n",
    "    earnings_factor = min(row['driver_earnings'] / 100, 1)  # Cap at 1\n",
    "    prob += 0.15 * earnings_factor\n",
    "    \n",
    "    # Adjust based on trip distance (slight negative for very long trips)\n",
    "    if row['estimated_trip_distance_km'] > 20:\n",
    "        prob -= 0.05\n",
    "    \n",
    "    # Adjust based on weather (negative for bad weather)\n",
    "    if row['weather_condition'] == 'Heavy Rain':\n",
    "        prob -= 0.1\n",
    "    elif row['weather_condition'] == 'Snow':\n",
    "        prob -= 0.15\n",
    "    \n",
    "    # Adjust based on traffic (negative for high traffic)\n",
    "    if row['traffic_congestion_level'] == 'High':\n",
    "        prob -= 0.05\n",
    "    elif row['traffic_congestion_level'] == 'Severe':\n",
    "        prob -= 0.1\n",
    "    \n",
    "    # Adjust based on hours already worked (negative if worked many hours)\n",
    "    if row['hours_already_worked'] > 8:\n",
    "        prob -= 0.2 * min((row['hours_already_worked'] - 8) / 4, 1)\n",
    "    \n",
    "    # Adjust based on time of day (higher during peak hours, though no surge pricing)\n",
    "    if row['is_peak_hour']:\n",
    "        prob += 0.05\n",
    "    elif row['hour_of_day'] in [2, 3, 4, 5]:  # Late night/early morning\n",
    "        prob -= 0.1\n",
    "    \n",
    "    # Adjust based on day of week (higher on weekends)\n",
    "    if row['day_of_week'] >= 5:  # Weekend\n",
    "        prob += 0.05\n",
    "    \n",
    "    # Ensure probability is between 0 and 1\n",
    "    return max(0.01, min(0.99, prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate acceptance probability and determine acceptance\n",
    "df['acceptance_probability'] = df.apply(calculate_acceptance_probability, axis=1)\n",
    "df['accepted_ride'] = df['acceptance_probability'].apply(lambda x: np.random.random() < x)\n",
    "\n",
    "# Convert boolean to int for easier analysis\n",
    "df['accepted_ride'] = df['accepted_ride'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns for clarity\n",
    "column_order = [\n",
    "    'driver_id', 'timestamp', 'hour_of_day', 'day_of_week', 'is_peak_hour',\n",
    "    'service_type', 'historical_acceptance_rate', \n",
    "    'distance_to_pickup_km', 'estimated_trip_distance_km', \n",
    "    'estimated_trip_time_min', 'fare_amount', 'driver_earnings',\n",
    "    'weather_condition', 'traffic_congestion_level', 'hours_already_worked', \n",
    "    'acceptance_probability', 'accepted_ride'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  driver_id            timestamp  hour_of_day  day_of_week  is_peak_hour  \\\n",
      "0      D027  2024-01-09 09:00:00            9            1          True   \n",
      "1      D022  2024-01-08 06:00:00            6            0         False   \n",
      "2      D037  2024-01-11 03:00:00            3            3         False   \n",
      "3      D019  2024-01-12 04:00:00            4            4         False   \n",
      "4      D039  2024-01-19 13:00:00           13            4         False   \n",
      "\n",
      "  service_type  historical_acceptance_rate  distance_to_pickup_km  \\\n",
      "0         Auto                    0.829146               0.593980   \n",
      "1         Bike                    0.820821               1.868333   \n",
      "2         Bike                    0.737274               3.407446   \n",
      "3         Auto                    0.830282               0.196544   \n",
      "4         Auto                    0.843371               0.645289   \n",
      "\n",
      "   estimated_trip_distance_km  estimated_trip_time_min  fare_amount  \\\n",
      "0                    3.136819                 7.842048           85   \n",
      "1                    4.052944                10.132359           85   \n",
      "2                    7.673016                15.346032          135   \n",
      "3                   10.763404                21.526809          210   \n",
      "4                   13.307614                33.269035          270   \n",
      "\n",
      "   driver_earnings weather_condition traffic_congestion_level  \\\n",
      "0               85             Clear                   Medium   \n",
      "1               85            Cloudy                   Medium   \n",
      "2              135             Clear                      Low   \n",
      "3              210             Clear                      Low   \n",
      "4              270             Clear                   Medium   \n",
      "\n",
      "   hours_already_worked  acceptance_probability  accepted_ride  \n",
      "0              1.131891                0.990000              1  \n",
      "1              3.775516                0.990000              1  \n",
      "2              2.780996                0.875405              1  \n",
      "3              3.590066                0.969629              1  \n",
      "4              3.208903                0.990000              1  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save to CSV\n",
    "df.to_csv('namma_yatri_driver_acceptance_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate more!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  driver_id            timestamp  month  day  hour_of_day  day_of_week  \\\n",
      "0      D016  2024-08-26 04:34:00      8   26            4            0   \n",
      "1      D100  2024-08-10 06:32:00      8   10            6            5   \n",
      "2      D100  2024-06-30 19:38:00      6   30           19            6   \n",
      "3      D012  2024-06-12 08:26:00      6   12            8            2   \n",
      "4      D062  2024-07-15 13:31:00      7   15           13            0   \n",
      "5      D089  2024-05-28 19:12:00      5   28           19            1   \n",
      "6      D008  2024-06-04 10:04:00      6    4           10            1   \n",
      "7      D044  2024-08-25 20:31:00      8   25           20            6   \n",
      "8      D039  2024-05-06 05:05:00      5    6            5            0   \n",
      "9      D048  2024-05-10 05:55:00      5   10            5            4   \n",
      "\n",
      "   is_peak_hour service_type  driver_experience_months vehicle_quality  ...  \\\n",
      "0         False         Auto                         7          Medium  ...   \n",
      "1         False         Bike                        35          Medium  ...   \n",
      "2          True         Auto                        35          Medium  ...   \n",
      "3          True         Auto                        17             Low  ...   \n",
      "4         False         Auto                         4          Medium  ...   \n",
      "5          True         Auto                        22            High  ...   \n",
      "6          True         Auto                        28          Medium  ...   \n",
      "7          True         Auto                        31          Medium  ...   \n",
      "8         False         Auto                        25          Medium  ...   \n",
      "9         False         Bike                        27          Medium  ...   \n",
      "\n",
      "  distance_to_pickup_km  estimated_trip_distance_km  estimated_trip_time_min  \\\n",
      "0              2.643001                    6.818981                17.047452   \n",
      "1              0.311105                    5.584532                13.961330   \n",
      "2              1.826274                   11.171505                27.928762   \n",
      "3              0.073760                    3.520131                 8.800327   \n",
      "4              1.089767                    2.117627                 5.000000   \n",
      "5              0.024038                    5.408038                27.040190   \n",
      "6              0.693451                   12.057613                30.144033   \n",
      "7              3.144643                   14.402553                36.006383   \n",
      "8              0.853562                   12.113028                24.226056   \n",
      "9              0.198240                    6.367774                15.919436   \n",
      "\n",
      "   fare_amount  driver_earnings  weather_condition  traffic_congestion_level  \\\n",
      "0          145              145         Heavy Rain                       Low   \n",
      "1          100              100             Cloudy                    Medium   \n",
      "2          215              215              Clear                    Medium   \n",
      "3          100              100              Clear                    Medium   \n",
      "4           75               75              Clear                       Low   \n",
      "5          140              140              Clear                    Severe   \n",
      "6          270              270              Clear                    Medium   \n",
      "7          280              280         Heavy Rain                       Low   \n",
      "8          210              210              Clear                       Low   \n",
      "9          110              110              Clear                    Medium   \n",
      "\n",
      "  hours_already_worked acceptance_probability  accepted_ride  \n",
      "0             0.919074               0.742248              1  \n",
      "1             0.927426               0.990000              1  \n",
      "2             4.271283               0.990000              1  \n",
      "3             1.123643               0.990000              1  \n",
      "4             3.149615               0.895777              0  \n",
      "5             1.626090               0.982968              1  \n",
      "6             6.259933               0.990000              1  \n",
      "7             3.569098               0.942857              1  \n",
      "8             1.105210               0.938895              1  \n",
      "9             2.543285               0.990000              1  \n",
      "\n",
      "[10 rows x 22 columns]\n",
      "\n",
      "Dataset summary statistics:\n",
      "             month          day  hour_of_day  day_of_week  \\\n",
      "count  2500.000000  2500.000000  2500.000000  2500.000000   \n",
      "mean      6.489600    15.687200    11.480800     3.070800   \n",
      "std       1.113188     8.819959     6.903789     1.996041   \n",
      "min       5.000000     1.000000     0.000000     0.000000   \n",
      "25%       5.000000     8.000000     5.000000     1.000000   \n",
      "50%       6.000000    16.000000    11.000000     3.000000   \n",
      "75%       7.000000    23.000000    17.000000     5.000000   \n",
      "max       8.000000    31.000000    23.000000     6.000000   \n",
      "\n",
      "       driver_experience_months  historical_acceptance_rate  \\\n",
      "count               2500.000000                 2500.000000   \n",
      "mean                  17.902800                    0.698998   \n",
      "std                    9.973462                    0.138260   \n",
      "min                    2.000000                    0.135771   \n",
      "25%                    9.000000                    0.609325   \n",
      "50%                   17.000000                    0.709205   \n",
      "75%                   25.000000                    0.804072   \n",
      "max                   35.000000                    0.976502   \n",
      "\n",
      "       distance_to_pickup_km  estimated_trip_distance_km  \\\n",
      "count            2500.000000                 2500.000000   \n",
      "mean                2.009175                    8.298099   \n",
      "std                 1.995845                    4.515723   \n",
      "min                 0.000651                    1.122703   \n",
      "25%                 0.605065                    5.147749   \n",
      "50%                 1.364340                    7.394047   \n",
      "75%                 2.782480                   10.341303   \n",
      "max                18.576134                   43.714385   \n",
      "\n",
      "       estimated_trip_time_min  fare_amount  driver_earnings  \\\n",
      "count              2500.000000  2500.000000      2500.000000   \n",
      "mean                 22.073265   173.568000       173.568000   \n",
      "std                  13.855600    80.496219        80.496219   \n",
      "min                   5.000000    55.000000        55.000000   \n",
      "25%                  12.907349   120.000000       120.000000   \n",
      "50%                  18.657605   155.000000       155.000000   \n",
      "75%                  27.257955   205.000000       205.000000   \n",
      "max                 135.606272   880.000000       880.000000   \n",
      "\n",
      "       hours_already_worked  acceptance_probability  accepted_ride  \n",
      "count           2500.000000             2500.000000    2500.000000  \n",
      "mean               3.001654                0.928199       0.939200  \n",
      "std                1.731999                0.075129       0.239011  \n",
      "min                0.113302                0.585772       0.000000  \n",
      "25%                1.733173                0.882931       1.000000  \n",
      "50%                2.701927                0.958411       1.000000  \n",
      "75%                3.849817                0.990000       1.000000  \n",
      "max               10.761051                0.990000       1.000000  \n",
      "\n",
      "Dataset saved to 'namma_yatri_extended_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(124)  # Different seed for more variation\n",
    "\n",
    "# Number of samples to generate\n",
    "n_samples = 2500  # Increased sample size\n",
    "\n",
    "# Generate driver IDs (100 unique drivers)\n",
    "driver_ids = [f\"D{str(i).zfill(3)}\" for i in range(1, 101)]  # More unique drivers\n",
    "\n",
    "# Generate service types (auto, bike) for Namma Yatri\n",
    "service_types = np.random.choice(['Auto', 'Bike'], n_samples, p=[0.7, 0.3])\n",
    "\n",
    "# Generate data with different time period (May-August 2024)\n",
    "data = {\n",
    "    'driver_id': np.random.choice(driver_ids, n_samples),\n",
    "    'timestamp': [(datetime(2024, 5, 1) + timedelta(days=np.random.randint(0, 120), \n",
    "                                                   hours=np.random.randint(0, 24),\n",
    "                                                   minutes=np.random.randint(0, 60))).strftime(\"%Y-%m-%d %H:%M:%S\") \n",
    "                 for _ in range(n_samples)],\n",
    "    'service_type': service_types,\n",
    "    'historical_acceptance_rate': np.random.beta(7, 3, n_samples),\n",
    "    'distance_to_pickup_km': np.random.exponential(2, n_samples),\n",
    "    'estimated_trip_distance_km': np.random.lognormal(2, 0.5, n_samples),\n",
    "    'estimated_trip_time_min': np.zeros(n_samples),  # Will calculate based on distance and traffic\n",
    "    'weather_condition': np.zeros(n_samples, dtype=object),  # Will fill based on month and random factors\n",
    "    'traffic_congestion_level': np.zeros(n_samples, dtype=object),  # Will fill based on time and day\n",
    "    'is_peak_hour': np.zeros(n_samples, dtype=bool),  # Will fill based on time\n",
    "    'hours_already_worked': np.random.gamma(3, 1, n_samples),\n",
    "    'accepted_ride': np.zeros(n_samples, dtype=bool)  # Will fill this based on other features\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Extract time features\n",
    "df['datetime'] = pd.to_datetime(df['timestamp'])\n",
    "df['hour_of_day'] = df['datetime'].dt.hour\n",
    "df['day_of_week'] = df['datetime'].dt.dayofweek\n",
    "df['month'] = df['datetime'].dt.month\n",
    "df['day'] = df['datetime'].dt.day\n",
    "\n",
    "# Generate seasonal weather patterns\n",
    "def generate_weather(row):\n",
    "    month = row['month']\n",
    "    random_factor = np.random.random()\n",
    "    \n",
    "    # May-June: Mostly clear, some light rain\n",
    "    if month in [5, 6]:\n",
    "        if random_factor < 0.6:\n",
    "            return 'Clear'\n",
    "        elif random_factor < 0.8:\n",
    "            return 'Cloudy'\n",
    "        else:\n",
    "            return 'Light Rain'\n",
    "    \n",
    "    # July-August: Monsoon season, more rain\n",
    "    elif month in [7, 8]:\n",
    "        if random_factor < 0.3:\n",
    "            return 'Clear'\n",
    "        elif random_factor < 0.5:\n",
    "            return 'Cloudy'\n",
    "        elif random_factor < 0.8:\n",
    "            return 'Light Rain'\n",
    "        else:\n",
    "            return 'Heavy Rain'\n",
    "    \n",
    "    return 'Clear'  # Default\n",
    "\n",
    "df['weather_condition'] = df.apply(generate_weather, axis=1)\n",
    "\n",
    "# Generate traffic patterns based on time and day\n",
    "def generate_traffic(row):\n",
    "    hour = row['hour_of_day']\n",
    "    day = row['day_of_week']\n",
    "    random_factor = np.random.random()\n",
    "    \n",
    "    # Rush hour weekday traffic\n",
    "    if day < 5:  # Weekday\n",
    "        if (8 <= hour <= 10) or (17 <= hour <= 19):  # Morning/evening rush\n",
    "            if random_factor < 0.4:\n",
    "                return 'High'\n",
    "            elif random_factor < 0.7:\n",
    "                return 'Severe'\n",
    "            else:\n",
    "                return 'Medium'\n",
    "        elif (7 <= hour <= 11) or (16 <= hour <= 20):  # Extended rush periods\n",
    "            if random_factor < 0.4:\n",
    "                return 'Medium'\n",
    "            elif random_factor < 0.7:\n",
    "                return 'High'\n",
    "            else:\n",
    "                return 'Low'\n",
    "    \n",
    "    # Weekend traffic patterns\n",
    "    if day >= 5:  # Weekend\n",
    "        if 11 <= hour <= 20:  # Daytime shopping/leisure\n",
    "            if random_factor < 0.5:\n",
    "                return 'Medium'\n",
    "            elif random_factor < 0.8:\n",
    "                return 'High'\n",
    "            else:\n",
    "                return 'Low'\n",
    "    \n",
    "    # Late night traffic usually light\n",
    "    if 22 <= hour or hour <= 5:\n",
    "        if random_factor < 0.8:\n",
    "            return 'Low'\n",
    "        else:\n",
    "            return 'Medium'\n",
    "    \n",
    "    # Default times - mixed\n",
    "    if random_factor < 0.4:\n",
    "        return 'Low'\n",
    "    elif random_factor < 0.8:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'High'\n",
    "\n",
    "df['traffic_congestion_level'] = df.apply(generate_traffic, axis=1)\n",
    "\n",
    "# Determine peak hours (weekdays 7-10 AM and 5-8 PM, weekends 11 AM-8 PM)\n",
    "def is_peak_hour(row):\n",
    "    hour = row['hour_of_day']\n",
    "    day = row['day_of_week']\n",
    "    \n",
    "    if day < 5:  # Weekday\n",
    "        return (7 <= hour <= 10) or (17 <= hour <= 20)\n",
    "    else:  # Weekend\n",
    "        return 11 <= hour <= 20\n",
    "\n",
    "df['is_peak_hour'] = df.apply(is_peak_hour, axis=1)\n",
    "\n",
    "# Calculate estimated trip time based on distance and traffic\n",
    "def estimate_trip_time(row):\n",
    "    distance = row['estimated_trip_distance_km']\n",
    "    \n",
    "    # Base speed in km/min (converted from km/h)\n",
    "    if row['traffic_congestion_level'] == 'Low':\n",
    "        speed = 0.5  # 30 km/h\n",
    "    elif row['traffic_congestion_level'] == 'Medium':\n",
    "        speed = 0.4  # 24 km/h\n",
    "    elif row['traffic_congestion_level'] == 'High':\n",
    "        speed = 0.3  # 18 km/h\n",
    "    else:  # Severe\n",
    "        speed = 0.2  # 12 km/h\n",
    "    \n",
    "    # Adjust speed based on weather\n",
    "    if row['weather_condition'] == 'Heavy Rain':\n",
    "        speed *= 0.8\n",
    "    elif row['weather_condition'] == 'Light Rain':\n",
    "        speed *= 0.9\n",
    "    \n",
    "    # Adjust speed based on service type (bikes are faster in traffic)\n",
    "    if row['service_type'] == 'Bike' and row['traffic_congestion_level'] in ['High', 'Severe']:\n",
    "        speed *= 1.3\n",
    "    \n",
    "    # Calculate time with a minimum of 5 minutes\n",
    "    return max(5, distance / speed)\n",
    "\n",
    "df['estimated_trip_time_min'] = df.apply(estimate_trip_time, axis=1)\n",
    "\n",
    "# Calculate fare amount based on Namma Yatri pricing strategy with some seasonal adjustments\n",
    "def calculate_namma_yatri_fare(row):\n",
    "    distance = row['estimated_trip_distance_km']\n",
    "    time = row['estimated_trip_time_min']\n",
    "    service = row['service_type']\n",
    "    month = row['month']\n",
    "    \n",
    "    # Seasonal base price variations\n",
    "    month_factor = 1.0\n",
    "    if month in [6, 7]:  # Slight increase in rainy season\n",
    "        month_factor = 1.05\n",
    "    \n",
    "    # Set pricing based on service type for Namma Yatri\n",
    "    if service == 'Auto':\n",
    "        base_fare = np.random.uniform(30, 40) * month_factor\n",
    "        per_km_rate = np.random.uniform(12, 15) * month_factor\n",
    "        per_min_rate = np.random.uniform(1, 2) * month_factor\n",
    "    else:  # Bike\n",
    "        base_fare = 30 * month_factor\n",
    "        per_km_rate = np.random.uniform(10, 12) * month_factor\n",
    "        per_min_rate = 1 * month_factor\n",
    "    \n",
    "    # Calculate fare components\n",
    "    distance_fare = per_km_rate * distance\n",
    "    time_fare = per_min_rate * time\n",
    "    \n",
    "    # Add a small random factor (±5%) to simulate price variations\n",
    "    random_factor = np.random.uniform(0.95, 1.05)\n",
    "    \n",
    "    # Total fare (Namma Yatri has no surge)\n",
    "    total_fare = (base_fare + distance_fare + time_fare) * random_factor\n",
    "    \n",
    "    # Round to nearest 5 rupees\n",
    "    return round(total_fare / 5) * 5\n",
    "\n",
    "df['fare_amount'] = df.apply(calculate_namma_yatri_fare, axis=1)\n",
    "\n",
    "# For Namma Yatri, driver earnings equal fare amount (0% commission)\n",
    "df['driver_earnings'] = df['fare_amount']\n",
    "\n",
    "# Generate driver data with more variation\n",
    "# Create a dictionary to track driver stats\n",
    "driver_stats = {}\n",
    "for driver_id in driver_ids:\n",
    "    # Generate varied driver characteristics\n",
    "    driver_stats[driver_id] = {\n",
    "        'experience_months': np.random.randint(1, 36),  # 1 month to 3 years experience\n",
    "        'vehicle_quality': np.random.choice(['Low', 'Medium', 'High'], p=[0.2, 0.6, 0.2]),\n",
    "        'preferred_areas': np.random.choice(['Urban', 'Suburban', 'Mixed'], p=[0.4, 0.3, 0.3]),\n",
    "    }\n",
    "\n",
    "# Add driver characteristics to main dataframe\n",
    "df['driver_experience_months'] = df['driver_id'].map(lambda x: driver_stats[x]['experience_months'])\n",
    "df['vehicle_quality'] = df['driver_id'].map(lambda x: driver_stats[x]['vehicle_quality'])\n",
    "df['preferred_areas'] = df['driver_id'].map(lambda x: driver_stats[x]['preferred_areas'])\n",
    "\n",
    "# Define acceptance probability based on features with more complexity\n",
    "def calculate_acceptance_probability(row):\n",
    "    prob = 0.75  # Base probability\n",
    "    \n",
    "    # Adjust based on historical acceptance rate (strong factor)\n",
    "    prob += 0.15 * row['historical_acceptance_rate']\n",
    "    \n",
    "    # Adjust based on distance to pickup (negative factor)\n",
    "    prob -= 0.05 * min(row['distance_to_pickup_km'], 10) / 2\n",
    "    \n",
    "    # Adjust based on earnings (positive factor)\n",
    "    earnings_factor = min(row['driver_earnings'] / 100, 1)  # Cap at 1\n",
    "    prob += 0.15 * earnings_factor\n",
    "    \n",
    "    # Adjust based on trip distance (slight negative for very long trips)\n",
    "    if row['estimated_trip_distance_km'] > 20:\n",
    "        prob -= 0.05\n",
    "    elif 5 <= row['estimated_trip_distance_km'] <= 15:\n",
    "        prob += 0.03  # Slight preference for medium-distance trips\n",
    "    \n",
    "    # Adjust based on weather (negative for bad weather)\n",
    "    if row['weather_condition'] == 'Heavy Rain':\n",
    "        prob -= 0.15\n",
    "    elif row['weather_condition'] == 'Light Rain':\n",
    "        prob -= 0.05\n",
    "    \n",
    "    # Adjust based on traffic (negative for high traffic)\n",
    "    if row['traffic_congestion_level'] == 'High':\n",
    "        prob -= 0.05\n",
    "    elif row['traffic_congestion_level'] == 'Severe':\n",
    "        prob -= 0.12\n",
    "    \n",
    "    # Adjust based on hours already worked (negative if worked many hours)\n",
    "    if row['hours_already_worked'] > 8:\n",
    "        prob -= 0.2 * min((row['hours_already_worked'] - 8) / 4, 1)\n",
    "    \n",
    "    # Adjust based on time of day\n",
    "    if row['is_peak_hour']:\n",
    "        prob += 0.05  # Higher during peak hours due to more ride opportunities\n",
    "    elif row['hour_of_day'] in [2, 3, 4, 5]:  # Late night/early morning\n",
    "        prob -= 0.1\n",
    "    \n",
    "    # Adjust based on day of week\n",
    "    if row['day_of_week'] >= 5:  # Weekend\n",
    "        prob += 0.05\n",
    "    \n",
    "    # Driver experience factors\n",
    "    if row['driver_experience_months'] > 24:\n",
    "        prob += 0.05  # Experienced drivers more likely to accept varied rides\n",
    "    elif row['driver_experience_months'] < 6:\n",
    "        prob -= 0.05  # New drivers may be more selective\n",
    "    \n",
    "    # Vehicle quality factor\n",
    "    if row['vehicle_quality'] == 'Low' and row['estimated_trip_distance_km'] > 15:\n",
    "        prob -= 0.05  # Lower quality vehicles less likely to take long trips\n",
    "    \n",
    "    # Ensure probability is between 0 and 1\n",
    "    return max(0.01, min(0.99, prob))\n",
    "\n",
    "# Calculate acceptance probability and determine acceptance\n",
    "df['acceptance_probability'] = df.apply(calculate_acceptance_probability, axis=1)\n",
    "df['accepted_ride'] = df['acceptance_probability'].apply(lambda x: np.random.random() < x)\n",
    "\n",
    "# Convert boolean to int for easier analysis\n",
    "df['accepted_ride'] = df['accepted_ride'].astype(int)\n",
    "\n",
    "# Reorder columns for clarity\n",
    "column_order = [\n",
    "    'driver_id', 'timestamp', 'month', 'day', 'hour_of_day', 'day_of_week', 'is_peak_hour',\n",
    "    'service_type', 'driver_experience_months', 'vehicle_quality', 'preferred_areas',\n",
    "    'historical_acceptance_rate', 'distance_to_pickup_km', 'estimated_trip_distance_km', \n",
    "    'estimated_trip_time_min', 'fare_amount', 'driver_earnings',\n",
    "    'weather_condition', 'traffic_congestion_level', 'hours_already_worked', \n",
    "    'acceptance_probability', 'accepted_ride'\n",
    "]\n",
    "df = df[column_order]\n",
    "\n",
    "# Print sample of the data\n",
    "print(df.head(10))\n",
    "print(\"\\nDataset summary statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('namma_yatri_extended_dataset.csv', index=False)\n",
    "print(\"\\nDataset saved to 'namma_yatri_extended_dataset.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combine the 2 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset saved as namma_yatri_merged_dataset.csv ✅\n"
     ]
    }
   ],
   "source": [
    "# Load both CSV files\n",
    "df1 = pd.read_csv(\"namma_yatri_extended_dataset.csv\")\n",
    "df2 = pd.read_csv(\"namma_yatri_driver_acceptance_dataset.csv\")\n",
    "\n",
    "# Combine the datasets\n",
    "merged_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Save the merged dataset\n",
    "merged_df.to_csv(\"namma_yatri_merged_dataset.csv\", index=False)\n",
    "\n",
    "print(\"Merged dataset saved as namma_yatri_merged_dataset.csv ✅\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate more!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  driver_id            timestamp  month  day  hour_of_day  day_of_week  \\\n",
      "0      D355  2024-06-25 11:05:52      6   25           11            1   \n",
      "1      D913  2024-07-31 20:09:15      7   31           20            2   \n",
      "2      D490  2024-08-03 06:52:02      8    3            6            5   \n",
      "3      D568  2024-05-06 11:07:43      5    6           11            0   \n",
      "4      D447  2024-05-17 20:37:06      5   17           20            4   \n",
      "5      D898  2024-07-24 18:54:31      7   24           18            2   \n",
      "6      D972  2024-07-21 03:20:34      7   21            3            6   \n",
      "7      D923  2024-06-02 15:45:42      6    2           15            6   \n",
      "8      D357  2024-08-23 02:04:06      8   23            2            4   \n",
      "9      D400  2024-07-01 17:49:48      7    1           17            0   \n",
      "\n",
      "   is_peak_hour service_type  driver_experience_months vehicle_quality  ...  \\\n",
      "0         False         Auto                        19            High  ...   \n",
      "1          True         Bike                         4            High  ...   \n",
      "2         False         Auto                        21          Medium  ...   \n",
      "3         False         Auto                         8          Medium  ...   \n",
      "4          True         Auto                        26            High  ...   \n",
      "5          True         Auto                        21            High  ...   \n",
      "6         False         Auto                        18          Medium  ...   \n",
      "7          True         Auto                        18          Medium  ...   \n",
      "8         False         Auto                         1            High  ...   \n",
      "9          True         Bike                         8          Medium  ...   \n",
      "\n",
      "  distance_to_pickup_km  estimated_trip_distance_km  estimated_trip_time_min  \\\n",
      "0              0.207434                    3.177355                 6.354710   \n",
      "1              2.093669                    4.350973                12.395934   \n",
      "2              1.468448                    4.451054                16.485384   \n",
      "3              3.623413                   10.561644                23.470320   \n",
      "4              1.211896                    9.938899                19.877798   \n",
      "5              0.154385                    5.673026                18.910086   \n",
      "6              0.432831                    9.280670                18.561339   \n",
      "7              0.099346                    7.594959                18.987396   \n",
      "8              4.203410                    3.753397                 9.383493   \n",
      "9              1.291811                   10.042716                27.896434   \n",
      "\n",
      "   fare_amount  driver_earnings  weather_condition  traffic_congestion_level  \\\n",
      "0           85               85              Clear                       Low   \n",
      "1           95               95         Light Rain                      High   \n",
      "2          110              110         Light Rain                      High   \n",
      "3          210              210         Light Rain                       Low   \n",
      "4          210              210              Clear                       Low   \n",
      "5          140              140              Clear                      High   \n",
      "6          205              205              Clear                       Low   \n",
      "7          175              175              Clear                    Medium   \n",
      "8          100              100              Clear                    Medium   \n",
      "9          180              180         Light Rain                    Medium   \n",
      "\n",
      "  hours_already_worked acceptance_probability  accepted_ride  \n",
      "0             3.091501               0.960986              1  \n",
      "1             1.783997               0.819718              0  \n",
      "2             3.686043               0.917622              1  \n",
      "3             3.119722               0.867116              1  \n",
      "4             2.286818               0.990000              1  \n",
      "5             1.699590               0.986442              1  \n",
      "6             1.457280               0.990000              1  \n",
      "7             2.485334               0.990000              1  \n",
      "8             0.944225               0.700046              0  \n",
      "9             2.827280               0.990000              1  \n",
      "\n",
      "[10 rows x 22 columns]\n",
      "\n",
      "Dataset summary statistics:\n",
      "              month           day   hour_of_day   day_of_week  \\\n",
      "count  50000.000000  50000.000000  50000.000000  50000.000000   \n",
      "mean       6.482840     15.707760     11.519440      2.982560   \n",
      "std        1.119201      8.808952      6.901656      1.978104   \n",
      "min        5.000000      1.000000      0.000000      0.000000   \n",
      "25%        5.000000      8.000000      6.000000      1.000000   \n",
      "50%        6.000000     16.000000     11.000000      3.000000   \n",
      "75%        7.000000     23.000000     18.000000      5.000000   \n",
      "max        8.000000     31.000000     23.000000      6.000000   \n",
      "\n",
      "       driver_experience_months  historical_acceptance_rate  \\\n",
      "count              50000.000000                50000.000000   \n",
      "mean                  18.101260                    0.701055   \n",
      "std                   10.074379                    0.138087   \n",
      "min                    1.000000                    0.140306   \n",
      "25%                   10.000000                    0.611632   \n",
      "50%                   18.000000                    0.714991   \n",
      "75%                   27.000000                    0.805176   \n",
      "max                   35.000000                    0.996390   \n",
      "\n",
      "       distance_to_pickup_km  estimated_trip_distance_km  \\\n",
      "count           50000.000000                50000.000000   \n",
      "mean                1.989407                    8.352160   \n",
      "std                 2.005385                    4.436893   \n",
      "min                 0.000022                    0.655073   \n",
      "25%                 0.567705                    5.261321   \n",
      "50%                 1.373919                    7.391042   \n",
      "75%                 2.745945                   10.310686   \n",
      "max                21.771685                   58.653422   \n",
      "\n",
      "       estimated_trip_time_min   fare_amount  driver_earnings  \\\n",
      "count             50000.000000  50000.000000     50000.000000   \n",
      "mean                 22.187047    174.415100       174.415100   \n",
      "std                  13.729276     78.759352        78.759352   \n",
      "min                   5.000000     45.000000        45.000000   \n",
      "25%                  12.974926    120.000000       120.000000   \n",
      "50%                  18.782745    155.000000       155.000000   \n",
      "75%                  27.488944    210.000000       210.000000   \n",
      "max                 221.199009    980.000000       980.000000   \n",
      "\n",
      "       hours_already_worked  acceptance_probability  accepted_ride  \n",
      "count          50000.000000            50000.000000    50000.00000  \n",
      "mean               3.003282                0.929999        0.92950  \n",
      "std                1.728464                0.074805        0.25599  \n",
      "min                0.067564                0.477659        0.00000  \n",
      "25%                1.729560                0.890116        1.00000  \n",
      "50%                2.674051                0.960114        1.00000  \n",
      "75%                3.930997                0.990000        1.00000  \n",
      "max               16.037679                0.990000        1.00000  \n",
      "\n",
      "Dataset saved to 'namma_yatri_huhu_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(124)  # Different seed for more variation\n",
    "\n",
    "# Number of samples to generate\n",
    "n_samples = 50000  # Increased sample size\n",
    "\n",
    "# Generate driver IDs (100 unique drivers)\n",
    "driver_ids = [f\"D{str(i).zfill(3)}\" for i in range(1, 1001)]  # More unique drivers\n",
    "\n",
    "# Generate service types (auto, bike) for Namma Yatri\n",
    "service_types = np.random.choice(['Auto', 'Bike'], n_samples, p=[0.7, 0.3])\n",
    "\n",
    "# Generate timestamps efficiently\n",
    "start_date = datetime(2024, 5, 1)\n",
    "end_date = datetime(2024, 8, 31)\n",
    "date_range = (end_date - start_date).total_seconds()\n",
    "\n",
    "timestamps = [start_date + timedelta(seconds=np.random.uniform(0, date_range)) for _ in range(n_samples)]\n",
    "\n",
    "\n",
    "# Generate data with different time period (May-August 2024)\n",
    "data = {\n",
    "    'driver_id': np.random.choice(driver_ids, n_samples),\n",
    "    'timestamp': [ts.strftime(\"%Y-%m-%d %H:%M:%S\") for ts in timestamps],\n",
    "    'service_type': service_types,\n",
    "    'historical_acceptance_rate': np.random.beta(7, 3, n_samples),\n",
    "    'distance_to_pickup_km': np.random.exponential(2, n_samples),\n",
    "    'estimated_trip_distance_km': np.random.lognormal(2, 0.5, n_samples),\n",
    "    'estimated_trip_time_min': np.zeros(n_samples),  # Will calculate based on distance and traffic\n",
    "    'weather_condition': np.zeros(n_samples, dtype=object),  # Will fill based on month and random factors\n",
    "    'traffic_congestion_level': np.zeros(n_samples, dtype=object),  # Will fill based on time and day\n",
    "    'is_peak_hour': np.zeros(n_samples, dtype=bool),  # Will fill based on time\n",
    "    'hours_already_worked': np.random.gamma(3, 1, n_samples),\n",
    "    'accepted_ride': np.zeros(n_samples, dtype=bool)  # Will fill this based on other features\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Extract time features\n",
    "df['datetime'] = pd.to_datetime(df['timestamp'])\n",
    "df['hour_of_day'] = df['datetime'].dt.hour\n",
    "df['day_of_week'] = df['datetime'].dt.dayofweek\n",
    "df['month'] = df['datetime'].dt.month\n",
    "df['day'] = df['datetime'].dt.day\n",
    "\n",
    "# Generate seasonal weather patterns\n",
    "def generate_weather(row):\n",
    "    month = row['month']\n",
    "    random_factor = np.random.random()\n",
    "    \n",
    "    # May-June: Mostly clear, some light rain\n",
    "    if month in [5, 6]:\n",
    "        if random_factor < 0.6:\n",
    "            return 'Clear'\n",
    "        elif random_factor < 0.8:\n",
    "            return 'Cloudy'\n",
    "        else:\n",
    "            return 'Light Rain'\n",
    "    \n",
    "    # July-August: Monsoon season, more rain\n",
    "    elif month in [7, 8]:\n",
    "        if random_factor < 0.3:\n",
    "            return 'Clear'\n",
    "        elif random_factor < 0.5:\n",
    "            return 'Cloudy'\n",
    "        elif random_factor < 0.8:\n",
    "            return 'Light Rain'\n",
    "        else:\n",
    "            return 'Heavy Rain'\n",
    "    \n",
    "    return 'Clear'  # Default\n",
    "\n",
    "df['weather_condition'] = df.apply(generate_weather, axis=1)\n",
    "\n",
    "# Generate traffic patterns based on time and day\n",
    "def generate_traffic(row):\n",
    "    hour = row['hour_of_day']\n",
    "    day = row['day_of_week']\n",
    "    random_factor = np.random.random()\n",
    "    \n",
    "    # Rush hour weekday traffic\n",
    "    if day < 5:  # Weekday\n",
    "        if (8 <= hour <= 10) or (17 <= hour <= 19):  # Morning/evening rush\n",
    "            if random_factor < 0.4:\n",
    "                return 'High'\n",
    "            elif random_factor < 0.7:\n",
    "                return 'Severe'\n",
    "            else:\n",
    "                return 'Medium'\n",
    "        elif (7 <= hour <= 11) or (16 <= hour <= 20):  # Extended rush periods\n",
    "            if random_factor < 0.4:\n",
    "                return 'Medium'\n",
    "            elif random_factor < 0.7:\n",
    "                return 'High'\n",
    "            else:\n",
    "                return 'Low'\n",
    "    \n",
    "    # Weekend traffic patterns\n",
    "    if day >= 5:  # Weekend\n",
    "        if 11 <= hour <= 20:  # Daytime shopping/leisure\n",
    "            if random_factor < 0.5:\n",
    "                return 'Medium'\n",
    "            elif random_factor < 0.8:\n",
    "                return 'High'\n",
    "            else:\n",
    "                return 'Low'\n",
    "    \n",
    "    # Late night traffic usually light\n",
    "    if 22 <= hour or hour <= 5:\n",
    "        if random_factor < 0.8:\n",
    "            return 'Low'\n",
    "        else:\n",
    "            return 'Medium'\n",
    "    \n",
    "    # Default times - mixed\n",
    "    if random_factor < 0.4:\n",
    "        return 'Low'\n",
    "    elif random_factor < 0.8:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'High'\n",
    "\n",
    "df['traffic_congestion_level'] = df.apply(generate_traffic, axis=1)\n",
    "\n",
    "# Determine peak hours (weekdays 7-10 AM and 5-8 PM, weekends 11 AM-8 PM)\n",
    "def is_peak_hour(row):\n",
    "    hour = row['hour_of_day']\n",
    "    day = row['day_of_week']\n",
    "    \n",
    "    if day < 5:  # Weekday\n",
    "        return (7 <= hour <= 10) or (17 <= hour <= 20)\n",
    "    else:  # Weekend\n",
    "        return 11 <= hour <= 20\n",
    "\n",
    "df['is_peak_hour'] = df.apply(is_peak_hour, axis=1)\n",
    "\n",
    "# Calculate estimated trip time based on distance and traffic\n",
    "def estimate_trip_time(row):\n",
    "    distance = row['estimated_trip_distance_km']\n",
    "    \n",
    "    # Base speed in km/min (converted from km/h)\n",
    "    if row['traffic_congestion_level'] == 'Low':\n",
    "        speed = 0.5  # 30 km/h\n",
    "    elif row['traffic_congestion_level'] == 'Medium':\n",
    "        speed = 0.4  # 24 km/h\n",
    "    elif row['traffic_congestion_level'] == 'High':\n",
    "        speed = 0.3  # 18 km/h\n",
    "    else:  # Severe\n",
    "        speed = 0.2  # 12 km/h\n",
    "    \n",
    "    # Adjust speed based on weather\n",
    "    if row['weather_condition'] == 'Heavy Rain':\n",
    "        speed *= 0.8\n",
    "    elif row['weather_condition'] == 'Light Rain':\n",
    "        speed *= 0.9\n",
    "    \n",
    "    # Adjust speed based on service type (bikes are faster in traffic)\n",
    "    if row['service_type'] == 'Bike' and row['traffic_congestion_level'] in ['High', 'Severe']:\n",
    "        speed *= 1.3\n",
    "    \n",
    "    # Calculate time with a minimum of 5 minutes\n",
    "    return max(5, distance / speed)\n",
    "\n",
    "df['estimated_trip_time_min'] = df.apply(estimate_trip_time, axis=1)\n",
    "\n",
    "# Calculate fare amount based on Namma Yatri pricing strategy with some seasonal adjustments\n",
    "def calculate_namma_yatri_fare(row):\n",
    "    distance = row['estimated_trip_distance_km']\n",
    "    time = row['estimated_trip_time_min']\n",
    "    service = row['service_type']\n",
    "    month = row['month']\n",
    "    \n",
    "    # Seasonal base price variations\n",
    "    month_factor = 1.0\n",
    "    if month in [6, 7]:  # Slight increase in rainy season\n",
    "        month_factor = 1.05\n",
    "    \n",
    "    # Set pricing based on service type for Namma Yatri\n",
    "    if service == 'Auto':\n",
    "        base_fare = np.random.uniform(30, 40) * month_factor\n",
    "        per_km_rate = np.random.uniform(12, 15) * month_factor\n",
    "        per_min_rate = np.random.uniform(1, 2) * month_factor\n",
    "    else:  # Bike\n",
    "        base_fare = 30 * month_factor\n",
    "        per_km_rate = np.random.uniform(10, 12) * month_factor\n",
    "        per_min_rate = 1 * month_factor\n",
    "    \n",
    "    # Calculate fare components\n",
    "    distance_fare = per_km_rate * distance\n",
    "    time_fare = per_min_rate * time\n",
    "    \n",
    "    # Add a small random factor (±5%) to simulate price variations\n",
    "    random_factor = np.random.uniform(0.95, 1.05)\n",
    "    \n",
    "    # Total fare (Namma Yatri has no surge)\n",
    "    total_fare = (base_fare + distance_fare + time_fare) * random_factor\n",
    "    \n",
    "    # Round to nearest 5 rupees\n",
    "    return round(total_fare / 5) * 5\n",
    "\n",
    "df['fare_amount'] = df.apply(calculate_namma_yatri_fare, axis=1)\n",
    "\n",
    "# For Namma Yatri, driver earnings equal fare amount (0% commission)\n",
    "df['driver_earnings'] = df['fare_amount']\n",
    "\n",
    "# Generate driver data with more variation\n",
    "# Create a dictionary to track driver stats\n",
    "driver_stats = {}\n",
    "for driver_id in driver_ids:\n",
    "    # Generate varied driver characteristics\n",
    "    driver_stats[driver_id] = {\n",
    "        'experience_months': np.random.randint(1, 36),  # 1 month to 3 years experience\n",
    "        'vehicle_quality': np.random.choice(['Low', 'Medium', 'High'], p=[0.2, 0.6, 0.2]),\n",
    "        'preferred_areas': np.random.choice(['Urban', 'Suburban', 'Mixed'], p=[0.4, 0.3, 0.3]),\n",
    "    }\n",
    "\n",
    "# Add driver characteristics to main dataframe\n",
    "df['driver_experience_months'] = df['driver_id'].map(lambda x: driver_stats[x]['experience_months'])\n",
    "df['vehicle_quality'] = df['driver_id'].map(lambda x: driver_stats[x]['vehicle_quality'])\n",
    "df['preferred_areas'] = df['driver_id'].map(lambda x: driver_stats[x]['preferred_areas'])\n",
    "\n",
    "# Define acceptance probability based on features with more complexity\n",
    "def calculate_acceptance_probability(row):\n",
    "    prob = 0.75  # Base probability\n",
    "    \n",
    "    # Adjust based on historical acceptance rate (strong factor)\n",
    "    prob += 0.15 * row['historical_acceptance_rate']\n",
    "    \n",
    "    # Adjust based on distance to pickup (negative factor)\n",
    "    prob -= 0.05 * min(row['distance_to_pickup_km'], 10) / 2\n",
    "    \n",
    "    # Adjust based on earnings (positive factor)\n",
    "    earnings_factor = min(row['driver_earnings'] / 100, 1)  # Cap at 1\n",
    "    prob += 0.15 * earnings_factor\n",
    "    \n",
    "    # Adjust based on trip distance (slight negative for very long trips)\n",
    "    if row['estimated_trip_distance_km'] > 20:\n",
    "        prob -= 0.05\n",
    "    elif 5 <= row['estimated_trip_distance_km'] <= 15:\n",
    "        prob += 0.03  # Slight preference for medium-distance trips\n",
    "    \n",
    "    # Adjust based on weather (negative for bad weather)\n",
    "    if row['weather_condition'] == 'Heavy Rain':\n",
    "        prob -= 0.15\n",
    "    elif row['weather_condition'] == 'Light Rain':\n",
    "        prob -= 0.05\n",
    "    \n",
    "    # Adjust based on traffic (negative for high traffic)\n",
    "    if row['traffic_congestion_level'] == 'High':\n",
    "        prob -= 0.05\n",
    "    elif row['traffic_congestion_level'] == 'Severe':\n",
    "        prob -= 0.12\n",
    "    \n",
    "    # Adjust based on hours already worked (negative if worked many hours)\n",
    "    if row['hours_already_worked'] > 8:\n",
    "        prob -= 0.2 * min((row['hours_already_worked'] - 8) / 4, 1)\n",
    "    \n",
    "    # Adjust based on time of day\n",
    "    if row['is_peak_hour']:\n",
    "        prob += 0.05  # Higher during peak hours due to more ride opportunities\n",
    "    elif row['hour_of_day'] in [2, 3, 4, 5]:  # Late night/early morning\n",
    "        prob -= 0.1\n",
    "    \n",
    "    # Adjust based on day of week\n",
    "    if row['day_of_week'] >= 5:  # Weekend\n",
    "        prob += 0.05\n",
    "    \n",
    "    # Driver experience factors\n",
    "    if row['driver_experience_months'] > 24:\n",
    "        prob += 0.05  # Experienced drivers more likely to accept varied rides\n",
    "    elif row['driver_experience_months'] < 6:\n",
    "        prob -= 0.05  # New drivers may be more selective\n",
    "    \n",
    "    # Vehicle quality factor\n",
    "    if row['vehicle_quality'] == 'Low' and row['estimated_trip_distance_km'] > 15:\n",
    "        prob -= 0.05  # Lower quality vehicles less likely to take long trips\n",
    "    \n",
    "    # Ensure probability is between 0 and 1\n",
    "    return max(0.01, min(0.99, prob))\n",
    "\n",
    "# Calculate acceptance probability and determine acceptance\n",
    "df['acceptance_probability'] = df.apply(calculate_acceptance_probability, axis=1)\n",
    "df['accepted_ride'] = df['acceptance_probability'].apply(lambda x: np.random.random() < x)\n",
    "\n",
    "# Convert boolean to int for easier analysis\n",
    "df['accepted_ride'] = df['accepted_ride'].astype(int)\n",
    "\n",
    "# Reorder columns for clarity\n",
    "column_order = [\n",
    "    'driver_id', 'timestamp', 'month', 'day', 'hour_of_day', 'day_of_week', 'is_peak_hour',\n",
    "    'service_type', 'driver_experience_months', 'vehicle_quality', 'preferred_areas',\n",
    "    'historical_acceptance_rate', 'distance_to_pickup_km', 'estimated_trip_distance_km', \n",
    "    'estimated_trip_time_min', 'fare_amount', 'driver_earnings',\n",
    "    'weather_condition', 'traffic_congestion_level', 'hours_already_worked', \n",
    "    'acceptance_probability', 'accepted_ride'\n",
    "]\n",
    "df = df[column_order]\n",
    "\n",
    "# Print sample of the data\n",
    "print(df.head(10))\n",
    "print(\"\\nDataset summary statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('namma_yatri_huhu_dataset.csv', index=False)\n",
    "print(\"\\nDataset saved to 'namma_yatri_huhu_dataset.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge with the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset saved as namma_yatri_combined.csv ✅\n"
     ]
    }
   ],
   "source": [
    "# Load both CSV files\n",
    "df1 = pd.read_csv(\"namma_yatri_huhu_dataset.csv\")\n",
    "df2 = pd.read_csv(\"namma_yatri_merged_dataset.csv\")\n",
    "\n",
    "# Combine the datasets\n",
    "merged_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Save the merged dataset\n",
    "merged_df.to_csv(\"namma_yatri_combined.csv\", index=False)\n",
    "\n",
    "print(\"Merged dataset saved as namma_yatri_combined.csv ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: Accepted 95.94% : Rejected 4.06%\n",
      "Adjusted class distribution: Accepted 87.80% : Rejected 12.20%\n",
      "  driver_id            timestamp  month  day  hour_of_day  day_of_week  \\\n",
      "0      D355  2024-06-25 11:05:52      6   25           11            1   \n",
      "1      D913  2024-07-31 20:09:15      7   31           20            2   \n",
      "2      D490  2024-08-03 06:52:02      8    3            6            5   \n",
      "3      D568  2024-05-06 11:07:43      5    6           11            0   \n",
      "4      D447  2024-05-17 20:37:06      5   17           20            4   \n",
      "5      D898  2024-07-24 18:54:31      7   24           18            2   \n",
      "6      D972  2024-07-21 03:20:34      7   21            3            6   \n",
      "7      D923  2024-06-02 15:45:42      6    2           15            6   \n",
      "8      D357  2024-08-23 02:04:06      8   23            2            4   \n",
      "9      D400  2024-07-01 17:49:48      7    1           17            0   \n",
      "\n",
      "   is_peak_hour service_type  driver_experience_months vehicle_quality  ...  \\\n",
      "0         False         Auto                        19            High  ...   \n",
      "1          True         Bike                         4            High  ...   \n",
      "2         False         Auto                        21          Medium  ...   \n",
      "3         False         Auto                         8          Medium  ...   \n",
      "4          True         Auto                        26            High  ...   \n",
      "5          True         Auto                        21            High  ...   \n",
      "6         False         Auto                        18          Medium  ...   \n",
      "7          True         Auto                        18          Medium  ...   \n",
      "8         False         Auto                         1            High  ...   \n",
      "9          True         Bike                         8          Medium  ...   \n",
      "\n",
      "  distance_to_pickup_km  estimated_trip_distance_km  estimated_trip_time_min  \\\n",
      "0              0.207434                    3.177355                 6.354710   \n",
      "1              2.093669                    4.350973                12.395934   \n",
      "2              1.468448                    4.451054                16.485384   \n",
      "3              3.623413                   10.561644                23.470320   \n",
      "4              1.211896                    9.938899                19.877798   \n",
      "5              0.154385                    5.673026                18.910086   \n",
      "6              0.432831                    9.280670                18.561339   \n",
      "7              0.099346                    7.594959                18.987396   \n",
      "8              4.203410                    3.753397                 9.383493   \n",
      "9              1.291811                   10.042716                27.896434   \n",
      "\n",
      "   fare_amount  driver_earnings  weather_condition  traffic_congestion_level  \\\n",
      "0           85               85              Clear                       Low   \n",
      "1           95               95         Light Rain                      High   \n",
      "2          110              110         Light Rain                      High   \n",
      "3          210              210         Light Rain                       Low   \n",
      "4          210              210              Clear                       Low   \n",
      "5          140              140              Clear                      High   \n",
      "6          205              205              Clear                       Low   \n",
      "7          175              175              Clear                    Medium   \n",
      "8          100              100              Clear                    Medium   \n",
      "9          180              180         Light Rain                    Medium   \n",
      "\n",
      "  hours_already_worked acceptance_probability  accepted_ride  \n",
      "0             3.091501               0.990000              1  \n",
      "1             1.783997               0.827127              1  \n",
      "2             3.686043               0.990000              1  \n",
      "3             3.119722               0.990000              1  \n",
      "4             2.286818               0.990000              1  \n",
      "5             1.699590               0.990000              1  \n",
      "6             1.457280               0.990000              1  \n",
      "7             2.485334               0.990000              1  \n",
      "8             0.944225               0.771317              1  \n",
      "9             2.827280               0.990000              0  \n",
      "\n",
      "[10 rows x 22 columns]\n",
      "\n",
      "Dataset summary statistics:\n",
      "              month           day   hour_of_day   day_of_week  \\\n",
      "count  50000.000000  50000.000000  50000.000000  50000.000000   \n",
      "mean       6.482840     15.707760     11.519440      2.982560   \n",
      "std        1.119201      8.808952      6.901656      1.978104   \n",
      "min        5.000000      1.000000      0.000000      0.000000   \n",
      "25%        5.000000      8.000000      6.000000      1.000000   \n",
      "50%        6.000000     16.000000     11.000000      3.000000   \n",
      "75%        7.000000     23.000000     18.000000      5.000000   \n",
      "max        8.000000     31.000000     23.000000      6.000000   \n",
      "\n",
      "       driver_experience_months  historical_acceptance_rate  \\\n",
      "count              50000.000000                50000.000000   \n",
      "mean                  18.101260                    0.701055   \n",
      "std                   10.074379                    0.138087   \n",
      "min                    1.000000                    0.140306   \n",
      "25%                   10.000000                    0.611632   \n",
      "50%                   18.000000                    0.714991   \n",
      "75%                   27.000000                    0.805176   \n",
      "max                   35.000000                    0.996390   \n",
      "\n",
      "       distance_to_pickup_km  estimated_trip_distance_km  \\\n",
      "count           50000.000000                50000.000000   \n",
      "mean                1.989407                    8.352160   \n",
      "std                 2.005385                    4.436893   \n",
      "min                 0.000022                    0.655073   \n",
      "25%                 0.567705                    5.261321   \n",
      "50%                 1.373919                    7.391042   \n",
      "75%                 2.745945                   10.310686   \n",
      "max                21.771685                   58.653422   \n",
      "\n",
      "       estimated_trip_time_min   fare_amount  driver_earnings  \\\n",
      "count             50000.000000  50000.000000     50000.000000   \n",
      "mean                 22.187047    174.415100       174.415100   \n",
      "std                  13.729276     78.759352        78.759352   \n",
      "min                   5.000000     45.000000        45.000000   \n",
      "25%                  12.974926    120.000000       120.000000   \n",
      "50%                  18.782745    155.000000       155.000000   \n",
      "75%                  27.488944    210.000000       210.000000   \n",
      "max                 221.199009    980.000000       980.000000   \n",
      "\n",
      "       hours_already_worked  acceptance_probability  accepted_ride  \n",
      "count          50000.000000            50000.000000   50000.000000  \n",
      "mean               3.003282                0.959325       0.878000  \n",
      "std                1.728464                0.059131       0.327289  \n",
      "min                0.067564                0.475996       0.000000  \n",
      "25%                1.729560                0.952535       1.000000  \n",
      "50%                2.674051                0.990000       1.000000  \n",
      "75%                3.930997                0.990000       1.000000  \n",
      "max               16.037679                0.990000       1.000000  \n",
      "\n",
      "Dataset saved to 'namma_yatri_imbalanced_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(124)  # Different seed for more variation\n",
    "\n",
    "# Number of samples to generate\n",
    "n_samples = 50000  # Increased sample size\n",
    "\n",
    "# Generate driver IDs (1000 unique drivers)\n",
    "driver_ids = [f\"D{str(i).zfill(3)}\" for i in range(1, 1001)]  # More unique drivers\n",
    "\n",
    "# Generate service types (auto, bike) for Namma Yatri\n",
    "service_types = np.random.choice(['Auto', 'Bike'], n_samples, p=[0.7, 0.3])\n",
    "\n",
    "# Generate timestamps efficiently\n",
    "start_date = datetime(2024, 5, 1)\n",
    "end_date = datetime(2024, 8, 31)\n",
    "date_range = (end_date - start_date).total_seconds()\n",
    "\n",
    "timestamps = [start_date + timedelta(seconds=np.random.uniform(0, date_range)) for _ in range(n_samples)]\n",
    "\n",
    "# Generate data with different time period (May-August 2024)\n",
    "data = {\n",
    "    'driver_id': np.random.choice(driver_ids, n_samples),\n",
    "    'timestamp': [ts.strftime(\"%Y-%m-%d %H:%M:%S\") for ts in timestamps],\n",
    "    'service_type': service_types,\n",
    "    'historical_acceptance_rate': np.random.beta(7, 3, n_samples),\n",
    "    'distance_to_pickup_km': np.random.exponential(2, n_samples),\n",
    "    'estimated_trip_distance_km': np.random.lognormal(2, 0.5, n_samples),\n",
    "    'estimated_trip_time_min': np.zeros(n_samples),  # Will calculate based on distance and traffic\n",
    "    'weather_condition': np.zeros(n_samples, dtype=object),  # Will fill based on month and random factors\n",
    "    'traffic_congestion_level': np.zeros(n_samples, dtype=object),  # Will fill based on time and day\n",
    "    'is_peak_hour': np.zeros(n_samples, dtype=bool),  # Will fill based on time\n",
    "    'hours_already_worked': np.random.gamma(3, 1, n_samples),\n",
    "    'accepted_ride': np.zeros(n_samples, dtype=bool)  # Will fill this based on other features\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Extract time features\n",
    "df['datetime'] = pd.to_datetime(df['timestamp'])\n",
    "df['hour_of_day'] = df['datetime'].dt.hour\n",
    "df['day_of_week'] = df['datetime'].dt.dayofweek\n",
    "df['month'] = df['datetime'].dt.month\n",
    "df['day'] = df['datetime'].dt.day\n",
    "\n",
    "# Generate seasonal weather patterns\n",
    "def generate_weather(row):\n",
    "    month = row['month']\n",
    "    random_factor = np.random.random()\n",
    "    \n",
    "    # May-June: Mostly clear, some light rain\n",
    "    if month in [5, 6]:\n",
    "        if random_factor < 0.6:\n",
    "            return 'Clear'\n",
    "        elif random_factor < 0.8:\n",
    "            return 'Cloudy'\n",
    "        else:\n",
    "            return 'Light Rain'\n",
    "    \n",
    "    # July-August: Monsoon season, more rain\n",
    "    elif month in [7, 8]:\n",
    "        if random_factor < 0.3:\n",
    "            return 'Clear'\n",
    "        elif random_factor < 0.5:\n",
    "            return 'Cloudy'\n",
    "        elif random_factor < 0.8:\n",
    "            return 'Light Rain'\n",
    "        else:\n",
    "            return 'Heavy Rain'\n",
    "    \n",
    "    return 'Clear'  # Default\n",
    "\n",
    "df['weather_condition'] = df.apply(generate_weather, axis=1)\n",
    "\n",
    "# Generate traffic patterns based on time and day\n",
    "def generate_traffic(row):\n",
    "    hour = row['hour_of_day']\n",
    "    day = row['day_of_week']\n",
    "    random_factor = np.random.random()\n",
    "    \n",
    "    # Rush hour weekday traffic\n",
    "    if day < 5:  # Weekday\n",
    "        if (8 <= hour <= 10) or (17 <= hour <= 19):  # Morning/evening rush\n",
    "            if random_factor < 0.4:\n",
    "                return 'High'\n",
    "            elif random_factor < 0.7:\n",
    "                return 'Severe'\n",
    "            else:\n",
    "                return 'Medium'\n",
    "        elif (7 <= hour <= 11) or (16 <= hour <= 20):  # Extended rush periods\n",
    "            if random_factor < 0.4:\n",
    "                return 'Medium'\n",
    "            elif random_factor < 0.7:\n",
    "                return 'High'\n",
    "            else:\n",
    "                return 'Low'\n",
    "    \n",
    "    # Weekend traffic patterns\n",
    "    if day >= 5:  # Weekend\n",
    "        if 11 <= hour <= 20:  # Daytime shopping/leisure\n",
    "            if random_factor < 0.5:\n",
    "                return 'Medium'\n",
    "            elif random_factor < 0.8:\n",
    "                return 'High'\n",
    "            else:\n",
    "                return 'Low'\n",
    "    \n",
    "    # Late night traffic usually light\n",
    "    if 22 <= hour or hour <= 5:\n",
    "        if random_factor < 0.8:\n",
    "            return 'Low'\n",
    "        else:\n",
    "            return 'Medium'\n",
    "    \n",
    "    # Default times - mixed\n",
    "    if random_factor < 0.4:\n",
    "        return 'Low'\n",
    "    elif random_factor < 0.8:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'High'\n",
    "\n",
    "df['traffic_congestion_level'] = df.apply(generate_traffic, axis=1)\n",
    "\n",
    "# Determine peak hours (weekdays 7-10 AM and 5-8 PM, weekends 11 AM-8 PM)\n",
    "def is_peak_hour(row):\n",
    "    hour = row['hour_of_day']\n",
    "    day = row['day_of_week']\n",
    "    \n",
    "    if day < 5:  # Weekday\n",
    "        return (7 <= hour <= 10) or (17 <= hour <= 20)\n",
    "    else:  # Weekend\n",
    "        return 11 <= hour <= 20\n",
    "\n",
    "df['is_peak_hour'] = df.apply(is_peak_hour, axis=1)\n",
    "\n",
    "# Calculate estimated trip time based on distance and traffic\n",
    "def estimate_trip_time(row):\n",
    "    distance = row['estimated_trip_distance_km']\n",
    "    \n",
    "    # Base speed in km/min (converted from km/h)\n",
    "    if row['traffic_congestion_level'] == 'Low':\n",
    "        speed = 0.5  # 30 km/h\n",
    "    elif row['traffic_congestion_level'] == 'Medium':\n",
    "        speed = 0.4  # 24 km/h\n",
    "    elif row['traffic_congestion_level'] == 'High':\n",
    "        speed = 0.3  # 18 km/h\n",
    "    else:  # Severe\n",
    "        speed = 0.2  # 12 km/h\n",
    "    \n",
    "    # Adjust speed based on weather\n",
    "    if row['weather_condition'] == 'Heavy Rain':\n",
    "        speed *= 0.8\n",
    "    elif row['weather_condition'] == 'Light Rain':\n",
    "        speed *= 0.9\n",
    "    \n",
    "    # Adjust speed based on service type (bikes are faster in traffic)\n",
    "    if row['service_type'] == 'Bike' and row['traffic_congestion_level'] in ['High', 'Severe']:\n",
    "        speed *= 1.3\n",
    "    \n",
    "    # Calculate time with a minimum of 5 minutes\n",
    "    return max(5, distance / speed)\n",
    "\n",
    "df['estimated_trip_time_min'] = df.apply(estimate_trip_time, axis=1)\n",
    "\n",
    "# Calculate fare amount based on Namma Yatri pricing strategy with some seasonal adjustments\n",
    "def calculate_namma_yatri_fare(row):\n",
    "    distance = row['estimated_trip_distance_km']\n",
    "    time = row['estimated_trip_time_min']\n",
    "    service = row['service_type']\n",
    "    month = row['month']\n",
    "    \n",
    "    # Seasonal base price variations\n",
    "    month_factor = 1.0\n",
    "    if month in [6, 7]:  # Slight increase in rainy season\n",
    "        month_factor = 1.05\n",
    "    \n",
    "    # Set pricing based on service type for Namma Yatri\n",
    "    if service == 'Auto':\n",
    "        base_fare = np.random.uniform(30, 40) * month_factor\n",
    "        per_km_rate = np.random.uniform(12, 15) * month_factor\n",
    "        per_min_rate = np.random.uniform(1, 2) * month_factor\n",
    "    else:  # Bike\n",
    "        base_fare = 30 * month_factor\n",
    "        per_km_rate = np.random.uniform(10, 12) * month_factor\n",
    "        per_min_rate = 1 * month_factor\n",
    "    \n",
    "    # Calculate fare components\n",
    "    distance_fare = per_km_rate * distance\n",
    "    time_fare = per_min_rate * time\n",
    "    \n",
    "    # Add a small random factor (±5%) to simulate price variations\n",
    "    random_factor = np.random.uniform(0.95, 1.05)\n",
    "    \n",
    "    # Total fare (Namma Yatri has no surge)\n",
    "    total_fare = (base_fare + distance_fare + time_fare) * random_factor\n",
    "    \n",
    "    # Round to nearest 5 rupees\n",
    "    return round(total_fare / 5) * 5\n",
    "\n",
    "df['fare_amount'] = df.apply(calculate_namma_yatri_fare, axis=1)\n",
    "\n",
    "# For Namma Yatri, driver earnings equal fare amount (0% commission)\n",
    "df['driver_earnings'] = df['fare_amount']\n",
    "\n",
    "# Generate driver data with more variation\n",
    "# Create a dictionary to track driver stats\n",
    "driver_stats = {}\n",
    "for driver_id in driver_ids:\n",
    "    # Generate varied driver characteristics\n",
    "    driver_stats[driver_id] = {\n",
    "        'experience_months': np.random.randint(1, 36),  # 1 month to 3 years experience\n",
    "        'vehicle_quality': np.random.choice(['Low', 'Medium', 'High'], p=[0.2, 0.6, 0.2]),\n",
    "        'preferred_areas': np.random.choice(['Urban', 'Suburban', 'Mixed'], p=[0.4, 0.3, 0.3]),\n",
    "    }\n",
    "\n",
    "# Add driver characteristics to main dataframe\n",
    "df['driver_experience_months'] = df['driver_id'].map(lambda x: driver_stats[x]['experience_months'])\n",
    "df['vehicle_quality'] = df['driver_id'].map(lambda x: driver_stats[x]['vehicle_quality'])\n",
    "df['preferred_areas'] = df['driver_id'].map(lambda x: driver_stats[x]['preferred_areas'])\n",
    "\n",
    "# Define acceptance probability based on features with more complexity\n",
    "def calculate_acceptance_probability(row):\n",
    "    # Base probability - INCREASED to achieve higher acceptance rate\n",
    "    prob = 0.85  # Higher base probability to target 87.8% acceptance\n",
    "    \n",
    "    # Adjust based on historical acceptance rate (strong factor)\n",
    "    prob += 0.15 * row['historical_acceptance_rate']\n",
    "    \n",
    "    # Adjust based on pickup distance (negative factor)\n",
    "    prob -= 0.05 * min(row['distance_to_pickup_km'], 10) / 2\n",
    "    \n",
    "    # Adjust based on earnings (positive factor)\n",
    "    earnings_factor = min(row['driver_earnings'] / 100, 1)  # Cap at 1\n",
    "    prob += 0.15 * earnings_factor\n",
    "    \n",
    "    # Adjust based on trip distance\n",
    "    if row['estimated_trip_distance_km'] > 20:\n",
    "        prob -= 0.06\n",
    "    elif row['estimated_trip_distance_km'] > 15:\n",
    "        prob -= 0.03\n",
    "    elif 5 <= row['estimated_trip_distance_km'] <= 15:\n",
    "        prob += 0.04  # Preference for medium-distance trips\n",
    "    \n",
    "    # Adjust based on weather\n",
    "    if row['weather_condition'] == 'Heavy Rain':\n",
    "        prob -= 0.15\n",
    "    elif row['weather_condition'] == 'Light Rain':\n",
    "        prob -= 0.06\n",
    "    elif row['weather_condition'] == 'Cloudy':\n",
    "        prob -= 0.02\n",
    "    \n",
    "    # Adjust based on traffic\n",
    "    if row['traffic_congestion_level'] == 'High':\n",
    "        prob -= 0.07\n",
    "    elif row['traffic_congestion_level'] == 'Severe':\n",
    "        prob -= 0.12\n",
    "    elif row['traffic_congestion_level'] == 'Medium':\n",
    "        prob -= 0.02\n",
    "    \n",
    "    # Adjust based on hours worked\n",
    "    if row['hours_already_worked'] > 8:\n",
    "        prob -= 0.2 * min((row['hours_already_worked'] - 8) / 4, 1)\n",
    "    elif row['hours_already_worked'] > 6:\n",
    "        prob -= 0.08\n",
    "    \n",
    "    # Adjust based on time of day\n",
    "    if row['is_peak_hour']:\n",
    "        prob += 0.06  # Higher during peak hours due to more ride opportunities\n",
    "    elif row['hour_of_day'] in [2, 3, 4, 5]:  # Late night/early morning\n",
    "        prob -= 0.10\n",
    "    \n",
    "    # Adjust based on day of week\n",
    "    if row['day_of_week'] >= 5:  # Weekend\n",
    "        prob += 0.04\n",
    "    \n",
    "    # Adjust based on driver experience\n",
    "    if row['driver_experience_months'] > 24:\n",
    "        prob += 0.05  # Experienced drivers more likely to accept varied rides\n",
    "    elif row['driver_experience_months'] < 6:\n",
    "        prob -= 0.06  # New drivers may be more selective\n",
    "    \n",
    "    # Adjust based on vehicle quality\n",
    "    if row['vehicle_quality'] == 'Low' and row['estimated_trip_distance_km'] > 15:\n",
    "        prob -= 0.06\n",
    "    elif row['vehicle_quality'] == 'Medium' and row['estimated_trip_distance_km'] > 18:\n",
    "        prob -= 0.02\n",
    "    \n",
    "    # Adjust based on preferred areas\n",
    "    if row['preferred_areas'] == 'Urban' and row['traffic_congestion_level'] in ['High', 'Severe']:\n",
    "        prob -= 0.03\n",
    "    elif row['preferred_areas'] == 'Suburban' and row['estimated_trip_distance_km'] < 5:\n",
    "        prob -= 0.03\n",
    "    \n",
    "    # Adjust based on service type\n",
    "    if row['service_type'] == 'Bike' and row['weather_condition'] in ['Light Rain', 'Heavy Rain']:\n",
    "        prob -= 0.04\n",
    "    \n",
    "    # Add random variation\n",
    "    prob += np.random.normal(0, 0.04)\n",
    "    \n",
    "    # Ensure probability is between 0.01 and 0.99\n",
    "    return max(0.01, min(0.99, prob))\n",
    "\n",
    "# Calculate acceptance probability and determine acceptance\n",
    "df['acceptance_probability'] = df.apply(calculate_acceptance_probability, axis=1)\n",
    "df['accepted_ride'] = df['acceptance_probability'].apply(lambda x: np.random.random() < x)\n",
    "\n",
    "# Convert boolean to int for easier analysis\n",
    "df['accepted_ride'] = df['accepted_ride'].astype(int)\n",
    "\n",
    "# Calculate and print class distribution\n",
    "acceptance_rate = df['accepted_ride'].mean() * 100\n",
    "rejection_rate = 100 - acceptance_rate\n",
    "print(f\"Class distribution: Accepted {acceptance_rate:.2f}% : Rejected {rejection_rate:.2f}%\")\n",
    "\n",
    "# Target acceptance rate\n",
    "target_acceptance = 87.8  # The target acceptance rate\n",
    "\n",
    "# If the acceptance rate is not close to target, adjust it\n",
    "if abs(acceptance_rate - target_acceptance) > 0.5:  # If more than 0.5% off target\n",
    "    if acceptance_rate > target_acceptance:\n",
    "        # Too many accepted rides - flip some to rejected\n",
    "        current_accepted = df['accepted_ride'].sum()\n",
    "        target_accepted = int(target_acceptance * n_samples / 100)\n",
    "        to_flip = current_accepted - target_accepted\n",
    "        \n",
    "        if to_flip > 0:\n",
    "            # Get indices of accepted rides\n",
    "            accepted_indices = df[df['accepted_ride'] == 1].index.tolist()\n",
    "            # Randomly select indices to flip\n",
    "            flip_indices = np.random.choice(accepted_indices, size=to_flip, replace=False)\n",
    "            # Flip these from accepted to rejected\n",
    "            df.loc[flip_indices, 'accepted_ride'] = 0\n",
    "    else:\n",
    "        # Too few accepted rides - flip some to accepted\n",
    "        current_accepted = df['accepted_ride'].sum()\n",
    "        target_accepted = int(target_acceptance * n_samples / 100)\n",
    "        to_flip = target_accepted - current_accepted\n",
    "        \n",
    "        if to_flip > 0:\n",
    "            # Get indices of rejected rides\n",
    "            rejected_indices = df[df['accepted_ride'] == 0].index.tolist()\n",
    "            # Randomly select indices to flip\n",
    "            flip_indices = np.random.choice(rejected_indices, size=to_flip, replace=False)\n",
    "            # Flip these from rejected to accepted\n",
    "            df.loc[flip_indices, 'accepted_ride'] = 1\n",
    "    \n",
    "    # Recalculate and print new class distribution\n",
    "    new_acceptance_rate = df['accepted_ride'].mean() * 100\n",
    "    new_rejection_rate = 100 - new_acceptance_rate\n",
    "    print(f\"Adjusted class distribution: Accepted {new_acceptance_rate:.2f}% : Rejected {new_rejection_rate:.2f}%\")\n",
    "\n",
    "# Reorder columns for clarity\n",
    "column_order = [\n",
    "    'driver_id', 'timestamp', 'month', 'day', 'hour_of_day', 'day_of_week', 'is_peak_hour',\n",
    "    'service_type', 'driver_experience_months', 'vehicle_quality', 'preferred_areas',\n",
    "    'historical_acceptance_rate', 'distance_to_pickup_km', 'estimated_trip_distance_km', \n",
    "    'estimated_trip_time_min', 'fare_amount', 'driver_earnings',\n",
    "    'weather_condition', 'traffic_congestion_level', 'hours_already_worked', \n",
    "    'acceptance_probability', 'accepted_ride'\n",
    "]\n",
    "df = df[column_order]\n",
    "\n",
    "# Print sample of the data\n",
    "print(df.head(10))\n",
    "print(\"\\nDataset summary statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('namma_yatri_imbalanced_dataset.csv', index=False)\n",
    "print(\"\\nDataset saved to 'namma_yatri_imbalanced_dataset.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: Accepted 92.40% : Rejected 7.60%\n",
      "Adjusted class distribution: Accepted 87.80% : Rejected 12.20%\n",
      "\n",
      "Correlation with accepted_ride:\n",
      "acceptance_probability        0.772444\n",
      "driver_experience_months      0.099762\n",
      "estimated_trip_distance_km    0.090162\n",
      "fare_amount                   0.067320\n",
      "driver_earnings               0.067320\n",
      "day_of_week                   0.065728\n",
      "historical_acceptance_rate    0.049123\n",
      "hour_of_day                   0.026063\n",
      "day                          -0.008447\n",
      "estimated_trip_time_min      -0.023711\n",
      "hours_already_worked         -0.041750\n",
      "month                        -0.079372\n",
      "distance_to_pickup_km        -0.267750\n",
      "Name: accepted_ride, dtype: float64\n",
      "\n",
      "Categorical variable correlation ratios:\n",
      "weather_condition: 0.2824\n",
      "service_type: 0.2513\n",
      "traffic_congestion_level: 0.0789\n",
      "preferred_areas: 0.0294\n",
      "vehicle_quality: 0.0022\n",
      "\n",
      "Sample data:\n",
      "  driver_id            timestamp  month  day  hour_of_day  day_of_week  \\\n",
      "0      D355  2024-06-25 11:05:52      6   25           11            1   \n",
      "1      D913  2024-07-31 20:09:15      7   31           20            2   \n",
      "2      D490  2024-08-03 06:52:02      8    3            6            5   \n",
      "3      D568  2024-05-06 11:07:43      5    6           11            0   \n",
      "4      D447  2024-05-17 20:37:06      5   17           20            4   \n",
      "\n",
      "   is_peak_hour service_type  driver_experience_months vehicle_quality  ...  \\\n",
      "0         False         Auto                        19            High  ...   \n",
      "1          True         Bike                         4            High  ...   \n",
      "2         False         Auto                        21          Medium  ...   \n",
      "3         False         Auto                         8          Medium  ...   \n",
      "4          True         Auto                        26            High  ...   \n",
      "\n",
      "  distance_to_pickup_km  estimated_trip_distance_km  estimated_trip_time_min  \\\n",
      "0              0.207434                    3.177355                 7.943387   \n",
      "1              2.093669                    4.350973                14.503243   \n",
      "2              1.468448                    4.451054                22.255268   \n",
      "3              3.623413                   10.561644                33.005137   \n",
      "4              1.211896                    9.938899                41.412079   \n",
      "\n",
      "   fare_amount  driver_earnings  weather_condition  traffic_congestion_level  \\\n",
      "0           85               85              Clear                    Medium   \n",
      "1          115              115         Light Rain                      High   \n",
      "2          150              150         Light Rain                      High   \n",
      "3          245              245         Light Rain                    Medium   \n",
      "4          280              280         Heavy Rain                    Medium   \n",
      "\n",
      "  hours_already_worked acceptance_probability  accepted_ride  \n",
      "0             3.091501               0.990000              1  \n",
      "1             1.783997               0.544443              0  \n",
      "2             3.686043               0.990000              1  \n",
      "3             3.119722               0.990000              1  \n",
      "4             2.286818               0.990000              1  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "Dataset summary statistics:\n",
      "              month           day   hour_of_day   day_of_week  \\\n",
      "count  50000.000000  50000.000000  50000.000000  50000.000000   \n",
      "mean       6.482840     15.707760     11.519440      2.982560   \n",
      "std        1.119201      8.808952      6.901656      1.978104   \n",
      "min        5.000000      1.000000      0.000000      0.000000   \n",
      "25%        5.000000      8.000000      6.000000      1.000000   \n",
      "50%        6.000000     16.000000     11.000000      3.000000   \n",
      "75%        7.000000     23.000000     18.000000      5.000000   \n",
      "max        8.000000     31.000000     23.000000      6.000000   \n",
      "\n",
      "       driver_experience_months  historical_acceptance_rate  \\\n",
      "count              50000.000000                50000.000000   \n",
      "mean                  18.101260                    0.701055   \n",
      "std                   10.074379                    0.138087   \n",
      "min                    1.000000                    0.140306   \n",
      "25%                   10.000000                    0.611632   \n",
      "50%                   18.000000                    0.714991   \n",
      "75%                   27.000000                    0.805176   \n",
      "max                   35.000000                    0.996390   \n",
      "\n",
      "       distance_to_pickup_km  estimated_trip_distance_km  \\\n",
      "count           50000.000000                50000.000000   \n",
      "mean                1.989407                    8.352160   \n",
      "std                 2.005385                    4.436893   \n",
      "min                 0.000022                    0.655073   \n",
      "25%                 0.567705                    5.261321   \n",
      "50%                 1.373919                    7.391042   \n",
      "75%                 2.745945                   10.310686   \n",
      "max                21.771685                   58.653422   \n",
      "\n",
      "       estimated_trip_time_min   fare_amount  driver_earnings  \\\n",
      "count             50000.000000  50000.000000     50000.000000   \n",
      "mean                 28.940619    209.584800       209.584800   \n",
      "std                  23.683742    106.075919       106.075919   \n",
      "min                   5.000000     50.000000        50.000000   \n",
      "25%                  14.135736    140.000000       140.000000   \n",
      "50%                  22.108587    185.000000       185.000000   \n",
      "75%                  35.600164    250.000000       250.000000   \n",
      "max                 341.212908   1445.000000      1445.000000   \n",
      "\n",
      "       hours_already_worked  acceptance_probability  accepted_ride  \n",
      "count          50000.000000            50000.000000   50000.000000  \n",
      "mean               3.003282                0.924519       0.878000  \n",
      "std                1.728464                0.138546       0.327289  \n",
      "min                0.067564                0.010000       0.000000  \n",
      "25%                1.729560                0.933719       1.000000  \n",
      "50%                2.674051                0.990000       1.000000  \n",
      "75%                3.930997                0.990000       1.000000  \n",
      "max               16.037679                0.990000       1.000000  \n",
      "\n",
      "Dataset saved to 'namma_yatri_imbalanced_dataset_stronger_correlations.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(124)  # Different seed for more variation\n",
    "\n",
    "# Number of samples to generate\n",
    "n_samples = 50000  # Increased sample size\n",
    "\n",
    "# Generate driver IDs (1000 unique drivers)\n",
    "driver_ids = [f\"D{str(i).zfill(3)}\" for i in range(1, 1001)]  # More unique drivers\n",
    "\n",
    "# Generate service types (auto, bike) for Namma Yatri\n",
    "service_types = np.random.choice(['Auto', 'Bike'], n_samples, p=[0.7, 0.3])\n",
    "\n",
    "# Generate timestamps efficiently\n",
    "start_date = datetime(2024, 5, 1)\n",
    "end_date = datetime(2024, 8, 31)\n",
    "date_range = (end_date - start_date).total_seconds()\n",
    "\n",
    "timestamps = [start_date + timedelta(seconds=np.random.uniform(0, date_range)) for _ in range(n_samples)]\n",
    "\n",
    "# Generate data with different time period (May-August 2024)\n",
    "data = {\n",
    "    'driver_id': np.random.choice(driver_ids, n_samples),\n",
    "    'timestamp': [ts.strftime(\"%Y-%m-%d %H:%M:%S\") for ts in timestamps],\n",
    "    'service_type': service_types,\n",
    "    'historical_acceptance_rate': np.random.beta(7, 3, n_samples),\n",
    "    'distance_to_pickup_km': np.random.exponential(2, n_samples),\n",
    "    'estimated_trip_distance_km': np.random.lognormal(2, 0.5, n_samples),\n",
    "    'estimated_trip_time_min': np.zeros(n_samples),  # Will calculate based on distance and traffic\n",
    "    'weather_condition': np.zeros(n_samples, dtype=object),  # Will fill based on month and random factors\n",
    "    'traffic_congestion_level': np.zeros(n_samples, dtype=object),  # Will fill based on time and day\n",
    "    'is_peak_hour': np.zeros(n_samples, dtype=bool),  # Will fill based on time\n",
    "    'hours_already_worked': np.random.gamma(3, 1, n_samples),\n",
    "    'accepted_ride': np.zeros(n_samples, dtype=bool)  # Will fill this based on other features\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Extract time features\n",
    "df['datetime'] = pd.to_datetime(df['timestamp'])\n",
    "df['hour_of_day'] = df['datetime'].dt.hour\n",
    "df['day_of_week'] = df['datetime'].dt.dayofweek\n",
    "df['month'] = df['datetime'].dt.month\n",
    "df['day'] = df['datetime'].dt.day\n",
    "\n",
    "# Generate more extreme seasonal weather patterns\n",
    "def generate_weather(row):\n",
    "    month = row['month']\n",
    "    random_factor = np.random.random()\n",
    "    hour = row['hour_of_day']\n",
    "    \n",
    "    # May-June: Mostly clear, some light rain (more extreme in evenings)\n",
    "    if month in [5, 6]:\n",
    "        if hour >= 16 and random_factor < 0.4:  # Evening thunderstorms more likely\n",
    "            return 'Heavy Rain'\n",
    "        elif random_factor < 0.5:\n",
    "            return 'Clear'\n",
    "        elif random_factor < 0.7:\n",
    "            return 'Cloudy'\n",
    "        else:\n",
    "            return 'Light Rain'\n",
    "    \n",
    "    # July-August: Intense monsoon season\n",
    "    elif month in [7, 8]:\n",
    "        if random_factor < 0.25:\n",
    "            return 'Clear'\n",
    "        elif random_factor < 0.4:\n",
    "            return 'Cloudy'\n",
    "        elif random_factor < 0.6:\n",
    "            return 'Light Rain'\n",
    "        else:\n",
    "            return 'Heavy Rain'\n",
    "    \n",
    "    return 'Clear'  # Default\n",
    "\n",
    "df['weather_condition'] = df.apply(generate_weather, axis=1)\n",
    "\n",
    "# Generate more extreme traffic patterns based on time and day\n",
    "def generate_traffic(row):\n",
    "    hour = row['hour_of_day']\n",
    "    day = row['day_of_week']\n",
    "    month = row['month']\n",
    "    random_factor = np.random.random()\n",
    "    \n",
    "    # More extreme rush hour weekday traffic (especially in July-August rainy season)\n",
    "    seasonal_factor = 1.2 if month in [7, 8] else 1.0\n",
    "    \n",
    "    if day < 5:  # Weekday\n",
    "        if (8 <= hour <= 10) or (17 <= hour <= 19):  # Core rush hours\n",
    "            if random_factor < 0.3 * seasonal_factor:\n",
    "                return 'Severe'\n",
    "            elif random_factor < 0.7 * seasonal_factor:\n",
    "                return 'High'\n",
    "            else:\n",
    "                return 'Medium'\n",
    "        elif (7 <= hour <= 11) or (16 <= hour <= 20):  # Extended rush periods\n",
    "            if random_factor < 0.2 * seasonal_factor:\n",
    "                return 'Severe'\n",
    "            elif random_factor < 0.5 * seasonal_factor:\n",
    "                return 'High'\n",
    "            else:\n",
    "                return 'Medium'\n",
    "    \n",
    "    # Weekend traffic patterns - more congested during rainy season\n",
    "    if day >= 5:  # Weekend\n",
    "        if 11 <= hour <= 20:  # Daytime shopping/leisure\n",
    "            if random_factor < 0.3 * seasonal_factor:\n",
    "                return 'High'\n",
    "            elif random_factor < 0.6 * seasonal_factor:\n",
    "                return 'Medium'\n",
    "            else:\n",
    "                return 'Low'\n",
    "    \n",
    "    # Late night traffic usually light\n",
    "    if 22 <= hour or hour <= 5:\n",
    "        if random_factor < 0.7:\n",
    "            return 'Low'\n",
    "        else:\n",
    "            return 'Medium'\n",
    "    \n",
    "    # Default times - mixed\n",
    "    if random_factor < 0.3:\n",
    "        return 'Low'\n",
    "    elif random_factor < 0.7:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'High'\n",
    "\n",
    "df['traffic_congestion_level'] = df.apply(generate_traffic, axis=1)\n",
    "\n",
    "# Determine peak hours (weekdays 7-10 AM and 5-8 PM, weekends 11 AM-8 PM)\n",
    "def is_peak_hour(row):\n",
    "    hour = row['hour_of_day']\n",
    "    day = row['day_of_week']\n",
    "    \n",
    "    if day < 5:  # Weekday\n",
    "        return (7 <= hour <= 10) or (17 <= hour <= 20)\n",
    "    else:  # Weekend\n",
    "        return 11 <= hour <= 20\n",
    "\n",
    "df['is_peak_hour'] = df.apply(is_peak_hour, axis=1)\n",
    "\n",
    "# Calculate estimated trip time based on distance and traffic with MORE EXTREME variations\n",
    "def estimate_trip_time(row):\n",
    "    distance = row['estimated_trip_distance_km']\n",
    "    \n",
    "    # Base speed in km/min (converted from km/h) - more extreme differences\n",
    "    if row['traffic_congestion_level'] == 'Low':\n",
    "        speed = 0.6  # 36 km/h\n",
    "    elif row['traffic_congestion_level'] == 'Medium':\n",
    "        speed = 0.4  # 24 km/h\n",
    "    elif row['traffic_congestion_level'] == 'High':\n",
    "        speed = 0.25  # 15 km/h\n",
    "    else:  # Severe\n",
    "        speed = 0.15  # 9 km/h - extremely slow\n",
    "    \n",
    "    # More extreme weather adjustments\n",
    "    if row['weather_condition'] == 'Heavy Rain':\n",
    "        speed *= 0.6  # Much slower in heavy rain\n",
    "    elif row['weather_condition'] == 'Light Rain':\n",
    "        speed *= 0.8  # Moderately slower in light rain\n",
    "    \n",
    "    # Adjust speed based on service type (bikes are faster in traffic)\n",
    "    if row['service_type'] == 'Bike' and row['traffic_congestion_level'] in ['High', 'Severe']:\n",
    "        speed *= 1.5  # Bikes much more advantageous in heavy traffic\n",
    "    \n",
    "    # Calculate time with a minimum of 5 minutes\n",
    "    return max(5, distance / speed)\n",
    "\n",
    "df['estimated_trip_time_min'] = df.apply(estimate_trip_time, axis=1)\n",
    "\n",
    "# Calculate fare amount based on Namma Yatri pricing with STRONGER seasonal and traffic adjustments\n",
    "def calculate_namma_yatri_fare(row):\n",
    "    distance = row['estimated_trip_distance_km']\n",
    "    time = row['estimated_trip_time_min']\n",
    "    service = row['service_type']\n",
    "    month = row['month']\n",
    "    weather = row['weather_condition']\n",
    "    traffic = row['traffic_congestion_level']\n",
    "    \n",
    "    # More extreme seasonal price variations\n",
    "    month_factor = 1.0\n",
    "    if month in [7, 8]:  # Significant increase during peak monsoon\n",
    "        month_factor = 1.15\n",
    "    elif month in [5, 6]:  # Slight increase in early monsoon\n",
    "        month_factor = 1.05\n",
    "    \n",
    "    # Weather factor - higher fares in worse weather\n",
    "    weather_factor = 1.0\n",
    "    if weather == 'Heavy Rain':\n",
    "        weather_factor = 1.2\n",
    "    elif weather == 'Light Rain':\n",
    "        weather_factor = 1.1\n",
    "    \n",
    "    # Traffic factor - higher rates during congestion\n",
    "    traffic_factor = 1.0\n",
    "    if traffic == 'Severe':\n",
    "        traffic_factor = 1.15\n",
    "    elif traffic == 'High':\n",
    "        traffic_factor = 1.1\n",
    "    \n",
    "    # Set pricing based on service type for Namma Yatri\n",
    "    if service == 'Auto':\n",
    "        base_fare = np.random.uniform(30, 40) * month_factor\n",
    "        per_km_rate = np.random.uniform(12, 15) * month_factor * weather_factor\n",
    "        per_min_rate = np.random.uniform(1, 2) * month_factor * traffic_factor\n",
    "    else:  # Bike\n",
    "        base_fare = 30 * month_factor\n",
    "        per_km_rate = np.random.uniform(10, 12) * month_factor * weather_factor\n",
    "        per_min_rate = 1 * month_factor * traffic_factor\n",
    "    \n",
    "    # Calculate fare components\n",
    "    distance_fare = per_km_rate * distance\n",
    "    time_fare = per_min_rate * time\n",
    "    \n",
    "    # Add a small random factor (±5%) to simulate price variations\n",
    "    random_factor = np.random.uniform(0.95, 1.05)\n",
    "    \n",
    "    # Total fare (Namma Yatri has no surge, but we're adding weather/traffic factors)\n",
    "    total_fare = (base_fare + distance_fare + time_fare) * random_factor\n",
    "    \n",
    "    # Round to nearest 5 rupees\n",
    "    return round(total_fare / 5) * 5\n",
    "\n",
    "df['fare_amount'] = df.apply(calculate_namma_yatri_fare, axis=1)\n",
    "\n",
    "# For Namma Yatri, driver earnings equal fare amount (0% commission)\n",
    "df['driver_earnings'] = df['fare_amount']\n",
    "\n",
    "# Generate driver data with more extreme variation\n",
    "# Create a dictionary to track driver stats\n",
    "driver_stats = {}\n",
    "for driver_id in driver_ids:\n",
    "    # Generate varied driver characteristics\n",
    "    driver_stats[driver_id] = {\n",
    "        'experience_months': np.random.randint(1, 36),  # 1 month to 3 years experience\n",
    "        'vehicle_quality': np.random.choice(['Low', 'Medium', 'High'], p=[0.2, 0.6, 0.2]),\n",
    "        'preferred_areas': np.random.choice(['Urban', 'Suburban', 'Mixed'], p=[0.4, 0.3, 0.3]),\n",
    "    }\n",
    "\n",
    "# Add driver characteristics to main dataframe\n",
    "df['driver_experience_months'] = df['driver_id'].map(lambda x: driver_stats[x]['experience_months'])\n",
    "df['vehicle_quality'] = df['driver_id'].map(lambda x: driver_stats[x]['vehicle_quality'])\n",
    "df['preferred_areas'] = df['driver_id'].map(lambda x: driver_stats[x]['preferred_areas'])\n",
    "\n",
    "# Define acceptance probability based on features with MUCH STRONGER relationships\n",
    "def calculate_acceptance_probability(row):\n",
    "    # Base probability\n",
    "    prob = 0.83  # Slightly lower base to allow for stronger feature effects\n",
    "    \n",
    "    # --- INCREASED IMPACT FACTORS ---\n",
    "    \n",
    "    # Strong impact from historical acceptance rate\n",
    "    prob += 0.2 * row['historical_acceptance_rate']\n",
    "    \n",
    "    # Distance to pickup - STRONGER negative impact\n",
    "    prob -= 0.12 * min(row['distance_to_pickup_km'], 10) / 2  # Increased from 0.05 to 0.12\n",
    "    \n",
    "    # EARNINGS - MUCH STRONGER positive impact\n",
    "    earnings_factor = min(row['driver_earnings'] / 100, 1.5)  # Increased cap to 1.5\n",
    "    prob += 0.25 * earnings_factor  # Increased from 0.15 to 0.25\n",
    "    \n",
    "    # Trip distance - STRONGER preferences\n",
    "    if row['estimated_trip_distance_km'] > 20:\n",
    "        prob -= 0.15  # Increased from 0.06 to 0.15\n",
    "    elif row['estimated_trip_distance_km'] > 15:\n",
    "        prob -= 0.08  # Increased from 0.03 to 0.08\n",
    "    elif 5 <= row['estimated_trip_distance_km'] <= 15:\n",
    "        prob += 0.09  # Increased from 0.04 to 0.09\n",
    "    \n",
    "    # WEATHER - MUCH STRONGER impact\n",
    "    if row['weather_condition'] == 'Heavy Rain':\n",
    "        prob -= 0.30  # Doubled from 0.15 to 0.30\n",
    "    elif row['weather_condition'] == 'Light Rain':\n",
    "        prob -= 0.15  # Increased from 0.06 to 0.15\n",
    "    elif row['weather_condition'] == 'Cloudy':\n",
    "        prob -= 0.05  # Increased from 0.02 to 0.05\n",
    "    \n",
    "    # TRAFFIC - MUCH STRONGER impact\n",
    "    if row['traffic_congestion_level'] == 'Severe':\n",
    "        prob -= 0.25  # Doubled from 0.12 to 0.25\n",
    "    elif row['traffic_congestion_level'] == 'High':\n",
    "        prob -= 0.15  # Doubled from 0.07 to 0.15\n",
    "    elif row['traffic_congestion_level'] == 'Medium':\n",
    "        prob -= 0.05  # Increased from 0.02 to 0.05\n",
    "    \n",
    "    # Hours worked - STRONGER impact\n",
    "    if row['hours_already_worked'] > 8:\n",
    "        prob -= 0.35 * min((row['hours_already_worked'] - 8) / 4, 1)  # Increased from 0.2 to 0.35\n",
    "    elif row['hours_already_worked'] > 6:\n",
    "        prob -= 0.15  # Increased from 0.08 to 0.15\n",
    "    \n",
    "    # Time of day - STRONGER impact\n",
    "    if row['is_peak_hour']:\n",
    "        prob += 0.12  # Doubled from 0.06 to 0.12\n",
    "    elif row['hour_of_day'] in [2, 3, 4, 5]:  # Late night/early morning\n",
    "        prob -= 0.20  # Doubled from 0.10 to 0.20\n",
    "    \n",
    "    # Day of week - STRONGER impact\n",
    "    if row['day_of_week'] >= 5:  # Weekend\n",
    "        prob += 0.08  # Doubled from 0.04 to 0.08\n",
    "    \n",
    "    # Driver experience - STRONGER impact\n",
    "    if row['driver_experience_months'] > 24:\n",
    "        prob += 0.10  # Doubled from 0.05 to 0.10\n",
    "    elif row['driver_experience_months'] < 6:\n",
    "        prob -= 0.12  # Doubled from 0.06 to 0.12\n",
    "    \n",
    "    # Vehicle quality - STRONGER impact\n",
    "    if row['vehicle_quality'] == 'Low' and row['estimated_trip_distance_km'] > 15:\n",
    "        prob -= 0.14  # Increased from 0.06 to 0.14\n",
    "    elif row['vehicle_quality'] == 'Medium' and row['estimated_trip_distance_km'] > 18:\n",
    "        prob -= 0.06  # Increased from 0.02 to 0.06\n",
    "    \n",
    "    # Preferred areas - STRONGER impact\n",
    "    if row['preferred_areas'] == 'Urban' and row['traffic_congestion_level'] in ['High', 'Severe']:\n",
    "        prob -= 0.08  # Increased from 0.03 to 0.08\n",
    "    elif row['preferred_areas'] == 'Suburban' and row['estimated_trip_distance_km'] < 5:\n",
    "        prob -= 0.08  # Increased from 0.03 to 0.08\n",
    "    \n",
    "    # Service type - STRONGER impact with weather\n",
    "    if row['service_type'] == 'Bike' and row['weather_condition'] in ['Light Rain', 'Heavy Rain']:\n",
    "        prob -= 0.18  # Significantly increased from 0.04 to 0.18\n",
    "        if row['weather_condition'] == 'Heavy Rain':\n",
    "            prob -= 0.12  # Additional penalty for bikes in heavy rain\n",
    "    \n",
    "    # Add combined effect of several factors\n",
    "    # If it's a severe traffic + heavy rain + bike + long distance, dramatically reduce acceptance\n",
    "    if (row['traffic_congestion_level'] == 'Severe' and \n",
    "        row['weather_condition'] == 'Heavy Rain' and \n",
    "        row['service_type'] == 'Bike' and\n",
    "        row['estimated_trip_distance_km'] > 15):\n",
    "        prob -= 0.30  # Severe combined penalty\n",
    "    \n",
    "    # Add high fare incentive: If fare is very high, increase acceptance likelihood\n",
    "    if row['fare_amount'] > 200:\n",
    "        prob += 0.15\n",
    "    \n",
    "    # Special time interaction: Drivers more likely to accept short trips at end of day\n",
    "    if row['hour_of_day'] >= 21 and row['estimated_trip_distance_km'] < 10:\n",
    "        prob += 0.10\n",
    "    \n",
    "    # Add random variation (reduced slightly to allow stronger deterministic factors)\n",
    "    prob += np.random.normal(0, 0.035)\n",
    "    \n",
    "    # Ensure probability is between 0.01 and 0.99\n",
    "    return max(0.01, min(0.99, prob))\n",
    "\n",
    "# Calculate acceptance probability and determine acceptance\n",
    "df['acceptance_probability'] = df.apply(calculate_acceptance_probability, axis=1)\n",
    "df['accepted_ride'] = df['acceptance_probability'].apply(lambda x: np.random.random() < x)\n",
    "\n",
    "# Convert boolean to int for easier analysis\n",
    "df['accepted_ride'] = df['accepted_ride'].astype(int)\n",
    "\n",
    "# Calculate and print class distribution\n",
    "acceptance_rate = df['accepted_ride'].mean() * 100\n",
    "rejection_rate = 100 - acceptance_rate\n",
    "print(f\"Class distribution: Accepted {acceptance_rate:.2f}% : Rejected {rejection_rate:.2f}%\")\n",
    "\n",
    "# Target acceptance rate\n",
    "target_acceptance = 87.8  # The target acceptance rate\n",
    "\n",
    "# If the acceptance rate is not close to target, adjust it\n",
    "if abs(acceptance_rate - target_acceptance) > 0.5:  # If more than 0.5% off target\n",
    "    if acceptance_rate > target_acceptance:\n",
    "        # Too many accepted rides - flip some to rejected\n",
    "        current_accepted = df['accepted_ride'].sum()\n",
    "        target_accepted = int(target_acceptance * n_samples / 100)\n",
    "        to_flip = current_accepted - target_accepted\n",
    "        \n",
    "        if to_flip > 0:\n",
    "            # Get indices of accepted rides with lowest probabilities\n",
    "            accepted_indices = df[df['accepted_ride'] == 1].sort_values('acceptance_probability').index[:to_flip].tolist()\n",
    "            # Flip these from accepted to rejected\n",
    "            df.loc[accepted_indices, 'accepted_ride'] = 0\n",
    "    else:\n",
    "        # Too few accepted rides - flip some to accepted\n",
    "        current_accepted = df['accepted_ride'].sum()\n",
    "        target_accepted = int(target_acceptance * n_samples / 100)\n",
    "        to_flip = target_accepted - current_accepted\n",
    "        \n",
    "        if to_flip > 0:\n",
    "            # Get indices of rejected rides with highest probabilities\n",
    "            rejected_indices = df[df['accepted_ride'] == 0].sort_values('acceptance_probability', ascending=False).index[:to_flip].tolist()\n",
    "            # Flip these from rejected to accepted\n",
    "            df.loc[rejected_indices, 'accepted_ride'] = 1\n",
    "    \n",
    "    # Recalculate and print new class distribution\n",
    "    new_acceptance_rate = df['accepted_ride'].mean() * 100\n",
    "    new_rejection_rate = 100 - new_acceptance_rate\n",
    "    print(f\"Adjusted class distribution: Accepted {new_acceptance_rate:.2f}% : Rejected {new_rejection_rate:.2f}%\")\n",
    "\n",
    "# Create correlation matrix and check correlations with accepted_ride\n",
    "print(\"\\nCorrelation with accepted_ride:\")\n",
    "numeric_df = df.select_dtypes(include=['number'])\n",
    "correlations = numeric_df.corr()['accepted_ride'].sort_values(ascending=False)\n",
    "print(correlations.drop('accepted_ride'))\n",
    "\n",
    "# Calculate correlation ratios for categorical features\n",
    "def correlation_ratio(categories, measurements):\n",
    "    categories = pd.Categorical(categories)\n",
    "    measurements = np.array(measurements)\n",
    "    \n",
    "    fcat, _ = pd.factorize(categories)\n",
    "    cat_num = np.max(fcat) + 1\n",
    "    y_avg_array = np.zeros(cat_num)\n",
    "    n_array = np.zeros(cat_num)\n",
    "    \n",
    "    for i in range(0, cat_num):\n",
    "        cat_measures = measurements[np.argwhere(fcat == i).flatten()]\n",
    "        n_array[i] = len(cat_measures)\n",
    "        y_avg_array[i] = np.average(cat_measures) if len(cat_measures) > 0 else 0\n",
    "    \n",
    "    y_total_avg = np.sum(np.multiply(y_avg_array, n_array)) / np.sum(n_array)\n",
    "    numerator = np.sum(np.multiply(n_array, np.square(np.subtract(y_avg_array, y_total_avg))))\n",
    "    denominator = np.sum(np.square(np.subtract(measurements, y_total_avg)))\n",
    "    \n",
    "    if denominator == 0:\n",
    "        return 0\n",
    "    return np.sqrt(numerator / denominator)\n",
    "\n",
    "# Calculate correlation ratio for categorical variables\n",
    "categorical_cols = ['weather_condition', 'traffic_congestion_level', 'service_type', \n",
    "                    'vehicle_quality', 'preferred_areas']\n",
    "cat_correlations = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    cat_correlations[col] = correlation_ratio(df[col], df['accepted_ride'])\n",
    "\n",
    "print(\"\\nCategorical variable correlation ratios:\")\n",
    "for col, corr in sorted(cat_correlations.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{col}: {corr:.4f}\")\n",
    "\n",
    "# Reorder columns for clarity\n",
    "column_order = [\n",
    "    'driver_id', 'timestamp', 'month', 'day', 'hour_of_day', 'day_of_week', 'is_peak_hour',\n",
    "    'service_type', 'driver_experience_months', 'vehicle_quality', 'preferred_areas',\n",
    "    'historical_acceptance_rate', 'distance_to_pickup_km', 'estimated_trip_distance_km', \n",
    "    'estimated_trip_time_min', 'fare_amount', 'driver_earnings',\n",
    "    'weather_condition', 'traffic_congestion_level', 'hours_already_worked', \n",
    "    'acceptance_probability', 'accepted_ride'\n",
    "]\n",
    "df = df[column_order]\n",
    "\n",
    "# Print sample of the data\n",
    "print(\"\\nSample data:\")\n",
    "print(df.head(5))\n",
    "print(\"\\nDataset summary statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('namma_yatri_imbalanced_dataset_stronger_correlations.csv', index=False)\n",
    "print(\"\\nDataset saved to 'namma_yatri_imbalanced_dataset_stronger_correlations.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
